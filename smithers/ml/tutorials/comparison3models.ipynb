{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.utils import get_seq_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8 #this can be changed\n",
    "data_path = '../datasets/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint_torch(epoch, model, path, optimizer):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy della rete ridotta a partire dalla VGG trainata dal checkpoint e con red_model trainato con train_kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix = torch.Size([50000, 4096])\n",
      "Epoch 0 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 100 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 150 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 200 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 250 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 300 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 350 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 400 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 450 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "L'inizializzazione ha impiegato 8.8 minuti\n",
      "Test Loss 0.00017220988927002547\n",
      " Top 1:  Accuracy: 6498.0/50000 (13.00%)\n",
      "Test Loss: 8.610494463501274\n",
      "Test Loss 0.0009103378942966462\n",
      " Top 1:  Accuracy: 1275.0/10000 (12.75%)\n",
      "Test Loss: 9.103378942966462\n",
      "EPOCH 1\n",
      "Train Loss kd: 9.212216138839722e-06\n",
      "Test Loss -0.0006444106830120087\n",
      " Top 1:  Accuracy: 8411.0/10000 (84.11%)\n",
      "Test Loss: -6.444106830120087\n",
      "EPOCH 2\n",
      "Train Loss kd: 2.5716087222099305e-06\n",
      "Test Loss -0.0007834380321788788\n",
      " Top 1:  Accuracy: 8649.0/10000 (86.49%)\n",
      "Test Loss: -7.834380321788788\n",
      "EPOCH 3\n",
      "Train Loss kd: 1.3555024862289429e-05\n",
      "Test Loss -0.0008292321416616441\n",
      " Top 1:  Accuracy: 8781.0/10000 (87.81%)\n",
      "Test Loss: -8.29232141661644\n",
      "EPOCH 4\n",
      "Train Loss kd: 1.7814967781305312e-07\n",
      "Test Loss -0.0009113735525274277\n",
      " Top 1:  Accuracy: 8853.0/10000 (88.53%)\n",
      "Test Loss: -9.113735525274278\n",
      "EPOCH 5\n",
      "Train Loss kd: 6.683323979377747e-06\n",
      "Test Loss -0.0009809486155700684\n",
      " Top 1:  Accuracy: 8852.0/10000 (88.52%)\n",
      "Test Loss: -9.809486155700684\n",
      "EPOCH 6\n",
      "Train Loss kd: 9.97372344136238e-07\n",
      "Test Loss -0.0010012650233078002\n",
      " Top 1:  Accuracy: 8868.0/10000 (88.68%)\n",
      "Test Loss: -10.012650233078002\n",
      "EPOCH 7\n",
      "Train Loss kd: 3.524695336818695e-07\n",
      "Test Loss -0.001032712427930832\n",
      " Top 1:  Accuracy: 8916.0/10000 (89.16%)\n",
      "Test Loss: -10.327124279308318\n",
      "EPOCH 8\n",
      "Train Loss kd: 1.9785167276859285e-06\n",
      "Test Loss -0.0010224991795635223\n",
      " Top 1:  Accuracy: 8898.0/10000 (88.98%)\n",
      "Test Loss: -10.224991795635223\n",
      "EPOCH 9\n",
      "Train Loss kd: 1.8968021497130393e-07\n",
      "Test Loss -0.0010713501422595978\n",
      " Top 1:  Accuracy: 8945.0/10000 (89.45%)\n",
      "Test Loss: -10.713501422595979\n",
      "EPOCH 10\n",
      "Train Loss kd: 4.551142454147339e-07\n",
      "Test Loss -0.0011109929700279238\n",
      " Top 1:  Accuracy: 8922.0/10000 (89.22%)\n",
      "Test Loss: -11.109929700279237\n",
      "Accuracy of network on test images is 89.2200....count:1250\n",
      "This took 21.4 minutes\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "\n",
    "\n",
    "VGGcomplete = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "VGGcomplete.make_layers()\n",
    "VGGcomplete._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGcomplete.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGcomplete, pretrained)\n",
    "seq_model_complete = get_seq_model(VGGcomplete)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "seq_model_complete = seq_model_complete.to(device)\n",
    "\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    " \"\"\"\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_complete = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_complete = netadapter_complete.reduce_net(seq_model_complete, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_complete, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "mid1 = time.time()\n",
    "print(\"L'inizializzazione ha impiegato {:.1f} minuti\".format((mid1-start1)/60))\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "\n",
    "rednet_flops[0], rednet_flops[1], rednet_flops[2] = [\n",
    "    Total_flops(red_model.premodel, device),\n",
    "    Total_flops(red_model.proj_model, device),\n",
    "    Total_flops(red_model.inout_map, device)] \"\"\"\n",
    "\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model_complete(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%50 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" print(\n",
    "      'Pre nnz = {:.2f}, proj_model nnz={:.2f}, FNN nnz={:.4f}'.format(\n",
    "      rednet_storage[0], rednet_storage[1],\n",
    "      rednet_storage[2]), flush=True) \"\"\"\n",
    "\"\"\" print(\n",
    "      'flops:  Pre = {:.2f}, proj_model = {:.2f}, FNN ={:.2f}'.format(\n",
    "       rednet_flops[0], rednet_flops[1], rednet_flops[2]), flush=True) \"\"\"\n",
    "\n",
    "optimizer_complete = torch.optim.Adam([{\n",
    "            'params': red_model_complete.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_complete.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_complete.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_complete, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 10\n",
    "filename = './cifar10_VGG16_RedNet_complete'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_complete,\n",
    "            VGGcomplete,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_complete,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "torch.save([red_model_complete.state_dict(), train_loss, test_loss], filename)\n",
    "end1 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_complete(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "time_VGGcomplete = end1 - start1\n",
    "print('This took {:.1f} minutes'.format(time_VGGcomplete/60), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da una VGG non trainata e con red_model non trainato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix = torch.Size([50000, 4096])\n",
      "Epoch 0 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 100 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 150 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 200 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 250 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 300 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 350 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 400 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 450 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Test Loss 2.697302400086075e-07\n",
      " Top 1:  Accuracy: 4794.0/50000 (9.59%)\n",
      "Test Loss: 0.013486512000430375\n",
      "Test Loss 7.490179128758609e-07\n",
      " Top 1:  Accuracy: 964.0/10000 (9.64%)\n",
      "Test Loss: 0.007490179128758609\n",
      "Accuracy of network on test images is 9.6400....count:1250\n",
      "This took 562.7 seconds\n"
     ]
    }
   ],
   "source": [
    "start2 = time.time()\n",
    "\n",
    "\n",
    "VGGuntrained = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGuntrained = VGGuntrained.to(device)\n",
    "VGGuntrained.make_layers()\n",
    "VGGuntrained._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGuntrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "seq_model_untrained = get_seq_model(VGGuntrained)\n",
    "VGGuntrained = VGGuntrained.to(device)\n",
    "seq_model_untrained = seq_model_untrained.to(device)\n",
    "\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_untrained = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_untrained = netadapter_untrained.reduce_net(seq_model_untrained, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_untrained, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\"\"\" \n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "\n",
    "rednet_flops[0], rednet_flops[1], rednet_flops[2] = [\n",
    "    Total_flops(red_model.premodel, device),\n",
    "    Total_flops(red_model.proj_model, device),\n",
    "    Total_flops(red_model.inout_map, device)] \"\"\"\n",
    "\"\"\" \n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model_untrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%50 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True) \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "optimizer_untrained = torch.optim.Adam([{\n",
    "            'params': red_model_untrained.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_untrained.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_untrained.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_untrained, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_untrained, device, test_loader))\n",
    "\n",
    "        \n",
    "filename = './cifar10_VGG16_RedNet_untrained'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "torch.save([red_model_untrained.state_dict(), train_loss, test_loss], filename)\n",
    "end2 = time.time()\n",
    "\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_untrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "time_VGGuntrained = end2 - start2\n",
    "print('This took {:.1f} seconds'.format(time_VGGuntrained), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da una VGG non trainata e con red_model trainato per 60 epoche su teacher non trainato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix = torch.Size([50000, 4096])\n",
      "Epoch 0 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 100 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 150 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 200 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 250 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 300 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 350 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 400 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 450 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Tempo di inizializzazione: 8.809595441818237 minuti\n",
      "Test Loss -6.89020123192668e-07\n",
      " Top 1:  Accuracy: 4942.0/50000 (9.88%)\n",
      "Test Loss: -0.034451006159633396\n",
      "Test Loss -3.393435773998499e-06\n",
      " Top 1:  Accuracy: 1097.0/10000 (10.97%)\n",
      "Test Loss: -0.03393435773998499\n",
      "EPOCH 1\n",
      "Train Loss kd: 2.346043586730957e-05\n",
      "Test Loss -0.0002705385774874687\n",
      " Top 1:  Accuracy: 5404.0/10000 (54.04%)\n",
      "Test Loss: -2.7053857748746872\n",
      "EPOCH 2\n",
      "Train Loss kd: 1.7225302457809448e-05\n",
      "Test Loss -0.0004263353899860382\n",
      " Top 1:  Accuracy: 6362.0/10000 (63.62%)\n",
      "Test Loss: -4.263353899860382\n",
      "EPOCH 3\n",
      "Train Loss kd: 1.6269389390945435e-05\n",
      "Test Loss -0.000463972950963974\n",
      " Top 1:  Accuracy: 6889.0/10000 (68.89%)\n",
      "Test Loss: -4.63972950963974\n",
      "EPOCH 4\n",
      "Train Loss kd: 2.366685390472412e-05\n",
      "Test Loss -0.0005089603350448608\n",
      " Top 1:  Accuracy: 7021.0/10000 (70.21%)\n",
      "Test Loss: -5.089603350448608\n",
      "EPOCH 5\n",
      "Train Loss kd: 3.2937350273132324e-05\n",
      "Test Loss -0.0005176158546161652\n",
      " Top 1:  Accuracy: 7260.0/10000 (72.60%)\n",
      "Test Loss: -5.176158546161652\n",
      "EPOCH 6\n",
      "Train Loss kd: 6.08562707901001e-06\n",
      "Test Loss -0.0005832872010803222\n",
      " Top 1:  Accuracy: 7324.0/10000 (73.24%)\n",
      "Test Loss: -5.832872010803222\n",
      "EPOCH 7\n",
      "Train Loss kd: 2.252948760986328e-05\n",
      "Test Loss -0.0005814902127838135\n",
      " Top 1:  Accuracy: 7353.0/10000 (73.53%)\n",
      "Test Loss: -5.814902127838135\n",
      "EPOCH 8\n",
      "Train Loss kd: 9.433192014694214e-06\n",
      "Test Loss -0.000596162118473053\n",
      " Top 1:  Accuracy: 7487.0/10000 (74.87%)\n",
      "Test Loss: -5.96162118473053\n",
      "EPOCH 9\n",
      "Train Loss kd: 1.8966119289398195e-05\n",
      "Test Loss -0.0005965236669349671\n",
      " Top 1:  Accuracy: 7528.0/10000 (75.28%)\n",
      "Test Loss: -5.965236669349671\n",
      "EPOCH 10\n",
      "Train Loss kd: 6.56252920627594e-06\n",
      "Test Loss -0.0006269127143669128\n",
      " Top 1:  Accuracy: 7628.0/10000 (76.28%)\n",
      "Test Loss: -6.269127143669128\n",
      "EPOCH 11\n",
      "Train Loss kd: 1.2804809808731079e-05\n",
      "Test Loss -0.0006364693328475953\n",
      " Top 1:  Accuracy: 7624.0/10000 (76.24%)\n",
      "Test Loss: -6.364693328475952\n",
      "EPOCH 12\n",
      "Train Loss kd: 1.4151291847229003e-05\n",
      "Test Loss -0.0006267273602485657\n",
      " Top 1:  Accuracy: 7712.0/10000 (77.12%)\n",
      "Test Loss: -6.267273602485656\n",
      "EPOCH 13\n",
      "Train Loss kd: 1.7911547422409057e-05\n",
      "Test Loss -0.000629116676197052\n",
      " Top 1:  Accuracy: 7723.0/10000 (77.23%)\n",
      "Test Loss: -6.29116676197052\n",
      "EPOCH 14\n",
      "Train Loss kd: 4.7511589527130125e-06\n",
      "Test Loss -0.0006521546182441711\n",
      " Top 1:  Accuracy: 7733.0/10000 (77.33%)\n",
      "Test Loss: -6.521546182441711\n",
      "EPOCH 15\n",
      "Train Loss kd: 1.5687077045440673e-05\n",
      "Test Loss -0.0006499549633598328\n",
      " Top 1:  Accuracy: 7757.0/10000 (77.57%)\n",
      "Test Loss: -6.499549633598328\n",
      "EPOCH 16\n",
      "Train Loss kd: 9.90111231803894e-06\n",
      "Test Loss -0.0006607431699752808\n",
      " Top 1:  Accuracy: 7789.0/10000 (77.89%)\n",
      "Test Loss: -6.607431699752808\n",
      "EPOCH 17\n",
      "Train Loss kd: 9.481136202812195e-06\n",
      "Test Loss -0.0006701089546585083\n",
      " Top 1:  Accuracy: 7834.0/10000 (78.34%)\n",
      "Test Loss: -6.701089546585083\n",
      "EPOCH 18\n",
      "Train Loss kd: 1.2572121620178222e-05\n",
      "Test Loss -0.0006894956667518616\n",
      " Top 1:  Accuracy: 7806.0/10000 (78.06%)\n",
      "Test Loss: -6.894956667518616\n",
      "EPOCH 19\n",
      "Train Loss kd: 1.802720308303833e-05\n",
      "Test Loss -0.0006912314856910705\n",
      " Top 1:  Accuracy: 7861.0/10000 (78.61%)\n",
      "Test Loss: -6.912314856910705\n",
      "EPOCH 20\n",
      "Train Loss kd: 1.9162688255310058e-05\n",
      "Test Loss -0.0006841941813278198\n",
      " Top 1:  Accuracy: 7890.0/10000 (78.90%)\n",
      "Test Loss: -6.841941813278198\n",
      "EPOCH 21\n",
      "Train Loss kd: 5.905324220657349e-06\n",
      "Test Loss -0.0006884859794235229\n",
      " Top 1:  Accuracy: 7851.0/10000 (78.51%)\n",
      "Test Loss: -6.884859794235229\n",
      "EPOCH 22\n",
      "Train Loss kd: 1.7332727909088134e-05\n",
      "Test Loss -0.0006980501064109803\n",
      " Top 1:  Accuracy: 7888.0/10000 (78.88%)\n",
      "Test Loss: -6.980501064109802\n",
      "EPOCH 23\n",
      "Train Loss kd: 6.059948801994324e-06\n",
      "Test Loss -0.0006962399080276489\n",
      " Top 1:  Accuracy: 7908.0/10000 (79.08%)\n",
      "Test Loss: -6.962399080276489\n",
      "EPOCH 24\n",
      "Train Loss kd: 1.2740964889526368e-05\n",
      "Test Loss -0.000720719684638977\n",
      " Top 1:  Accuracy: 7940.0/10000 (79.40%)\n",
      "Test Loss: -7.20719684638977\n",
      "EPOCH 25\n",
      "Train Loss kd: 5.218029022216797e-06\n",
      "Test Loss -0.0007158706828308105\n",
      " Top 1:  Accuracy: 7930.0/10000 (79.30%)\n",
      "Test Loss: -7.158706828308105\n",
      "EPOCH 26\n",
      "Train Loss kd: 1.5109186172485352e-05\n",
      "Test Loss -0.0007307528882789611\n",
      " Top 1:  Accuracy: 7928.0/10000 (79.28%)\n",
      "Test Loss: -7.307528882789612\n",
      "EPOCH 27\n",
      "Train Loss kd: 8.85254681110382e-06\n",
      "Test Loss -0.0007051150554466248\n",
      " Top 1:  Accuracy: 7915.0/10000 (79.15%)\n",
      "Test Loss: -7.051150554466248\n",
      "EPOCH 28\n",
      "Train Loss kd: 1.0897262096405029e-05\n",
      "Test Loss -0.0007303339918899536\n",
      " Top 1:  Accuracy: 7969.0/10000 (79.69%)\n",
      "Test Loss: -7.303339918899536\n",
      "EPOCH 29\n",
      "Train Loss kd: 8.619493842124939e-06\n",
      "Test Loss -0.0007372892514228821\n",
      " Top 1:  Accuracy: 7990.0/10000 (79.90%)\n",
      "Test Loss: -7.372892514228821\n",
      "EPOCH 30\n",
      "Train Loss kd: 1.5037249326705932e-05\n",
      "Test Loss -0.0007312896560096741\n",
      " Top 1:  Accuracy: 7975.0/10000 (79.75%)\n",
      "Test Loss: -7.312896560096741\n",
      "EPOCH 31\n",
      "Train Loss kd: 7.255175113677978e-06\n",
      "Test Loss -0.0007294331674194336\n",
      " Top 1:  Accuracy: 7956.0/10000 (79.56%)\n",
      "Test Loss: -7.294331674194336\n",
      "EPOCH 32\n",
      "Train Loss kd: 8.739038109779357e-06\n",
      "Test Loss -0.000728500410861969\n",
      " Top 1:  Accuracy: 7973.0/10000 (79.73%)\n",
      "Test Loss: -7.28500410861969\n",
      "EPOCH 33\n",
      "Train Loss kd: 1.7108544111251832e-05\n",
      "Test Loss -0.0007344912452888488\n",
      " Top 1:  Accuracy: 7964.0/10000 (79.64%)\n",
      "Test Loss: -7.344912452888488\n",
      "EPOCH 34\n",
      "Train Loss kd: 3.7156787514686586e-06\n",
      "Test Loss -0.0007483916673278808\n",
      " Top 1:  Accuracy: 8010.0/10000 (80.10%)\n",
      "Test Loss: -7.4839166732788085\n",
      "EPOCH 35\n",
      "Train Loss kd: 1.5029906034469604e-05\n",
      "Test Loss -0.0007528461170959472\n",
      " Top 1:  Accuracy: 7937.0/10000 (79.37%)\n",
      "Test Loss: -7.528461170959472\n",
      "EPOCH 36\n",
      "Train Loss kd: 4.099648594856263e-06\n",
      "Test Loss -0.000727951065711975\n",
      " Top 1:  Accuracy: 7985.0/10000 (79.85%)\n",
      "Test Loss: -7.279510657119751\n",
      "EPOCH 37\n",
      "Train Loss kd: 4.776977300643921e-06\n",
      "Test Loss -0.0007453444910812377\n",
      " Top 1:  Accuracy: 8010.0/10000 (80.10%)\n",
      "Test Loss: -7.453444910812378\n",
      "EPOCH 38\n",
      "Train Loss kd: 7.417770028114319e-06\n",
      "Test Loss -0.0007484403401756286\n",
      " Top 1:  Accuracy: 7989.0/10000 (79.89%)\n",
      "Test Loss: -7.484403401756286\n",
      "EPOCH 39\n",
      "Train Loss kd: 6.419408321380615e-06\n",
      "Test Loss -0.0007419648260116576\n",
      " Top 1:  Accuracy: 8006.0/10000 (80.06%)\n",
      "Test Loss: -7.419648260116577\n",
      "EPOCH 40\n",
      "Train Loss kd: 1.3289085626602172e-05\n",
      "Test Loss -0.000772090635509491\n",
      " Top 1:  Accuracy: 8040.0/10000 (80.40%)\n",
      "Test Loss: -7.720906355094909\n",
      "EPOCH 41\n",
      "Train Loss kd: 9.905116558074952e-06\n",
      "Test Loss -0.0007574191421890259\n",
      " Top 1:  Accuracy: 8039.0/10000 (80.39%)\n",
      "Test Loss: -7.574191421890259\n",
      "EPOCH 42\n",
      "Train Loss kd: 7.172593474388123e-06\n",
      "Test Loss -0.000760311792793274\n",
      " Top 1:  Accuracy: 8033.0/10000 (80.33%)\n",
      "Test Loss: -7.60311792793274\n",
      "EPOCH 43\n",
      "Train Loss kd: 5.11372983455658e-06\n",
      "Test Loss -0.0007720310807418823\n",
      " Top 1:  Accuracy: 8054.0/10000 (80.54%)\n",
      "Test Loss: -7.720310807418823\n",
      "EPOCH 44\n",
      "Train Loss kd: 9.857687950134277e-06\n",
      "Test Loss -0.0007777770701599122\n",
      " Top 1:  Accuracy: 8029.0/10000 (80.29%)\n",
      "Test Loss: -7.777770701599121\n",
      "EPOCH 45\n",
      "Train Loss kd: 8.342045545578003e-06\n",
      "Test Loss -0.0007879872194099426\n",
      " Top 1:  Accuracy: 8014.0/10000 (80.14%)\n",
      "Test Loss: -7.879872194099426\n",
      "EPOCH 46\n",
      "Train Loss kd: 1.5091887712478638e-05\n",
      "Test Loss -0.0007709274894714355\n",
      " Top 1:  Accuracy: 8045.0/10000 (80.45%)\n",
      "Test Loss: -7.709274894714356\n",
      "EPOCH 47\n",
      "Train Loss kd: 1.0414689779281616e-05\n",
      "Test Loss -0.0007720802996444702\n",
      " Top 1:  Accuracy: 8051.0/10000 (80.51%)\n",
      "Test Loss: -7.720802996444702\n",
      "EPOCH 48\n",
      "Train Loss kd: 5.9637129306793216e-06\n",
      "Test Loss -0.000774284482460022\n",
      " Top 1:  Accuracy: 8061.0/10000 (80.61%)\n",
      "Test Loss: -7.74284482460022\n",
      "EPOCH 49\n",
      "Train Loss kd: 1.1404029130935668e-05\n",
      "Test Loss -0.0007735901655769349\n",
      " Top 1:  Accuracy: 8042.0/10000 (80.42%)\n",
      "Test Loss: -7.735901655769348\n",
      "EPOCH 50\n",
      "Train Loss kd: 4.0494966506958006e-06\n",
      "Test Loss -0.0007796910920143127\n",
      " Top 1:  Accuracy: 8068.0/10000 (80.68%)\n",
      "Test Loss: -7.7969109201431275\n",
      "EPOCH 51\n",
      "Train Loss kd: 7.757513523101807e-06\n",
      "Test Loss -0.0007771728517913818\n",
      " Top 1:  Accuracy: 8093.0/10000 (80.93%)\n",
      "Test Loss: -7.771728517913818\n",
      "EPOCH 52\n",
      "Train Loss kd: 5.34519612789154e-06\n",
      "Test Loss -0.0007738195758628845\n",
      " Top 1:  Accuracy: 8077.0/10000 (80.77%)\n",
      "Test Loss: -7.738195758628845\n",
      "EPOCH 53\n",
      "Train Loss kd: 1.247429370880127e-05\n",
      "Test Loss -0.0008004670509147644\n",
      " Top 1:  Accuracy: 8078.0/10000 (80.78%)\n",
      "Test Loss: -8.004670509147644\n",
      "EPOCH 54\n",
      "Train Loss kd: 3.607621192932129e-06\n",
      "Test Loss -0.0007729469466781616\n",
      " Top 1:  Accuracy: 8050.0/10000 (80.50%)\n",
      "Test Loss: -7.729469466781616\n",
      "EPOCH 55\n",
      "Train Loss kd: 1.2550725936889648e-05\n",
      "Test Loss -0.0008035532821273804\n",
      " Top 1:  Accuracy: 8087.0/10000 (80.87%)\n",
      "Test Loss: -8.035532821273804\n",
      "EPOCH 56\n",
      "Train Loss kd: 7.6080387830734255e-06\n",
      "Test Loss -0.0007849218673706055\n",
      " Top 1:  Accuracy: 8073.0/10000 (80.73%)\n",
      "Test Loss: -7.849218673706055\n",
      "EPOCH 57\n",
      "Train Loss kd: 1.1266261339187623e-05\n",
      "Test Loss -0.0007852506088256836\n",
      " Top 1:  Accuracy: 8096.0/10000 (80.96%)\n",
      "Test Loss: -7.852506088256836\n",
      "EPOCH 58\n",
      "Train Loss kd: 5.996559262275696e-06\n",
      "Test Loss -0.0007966148510360718\n",
      " Top 1:  Accuracy: 8079.0/10000 (80.79%)\n",
      "Test Loss: -7.966148510360718\n",
      "EPOCH 59\n",
      "Train Loss kd: 5.020756125450134e-06\n",
      "Test Loss -0.0008004966713333129\n",
      " Top 1:  Accuracy: 8095.0/10000 (80.95%)\n",
      "Test Loss: -8.004966713333129\n",
      "EPOCH 60\n",
      "Train Loss kd: 4.098587930202484e-06\n",
      "Test Loss -0.0008038160001754761\n",
      " Top 1:  Accuracy: 8132.0/10000 (81.32%)\n",
      "Test Loss: -8.038160001754761\n",
      "Accuracy of network on test images is 81.3200....count:1250\n",
      "Tempo totale 84.1 seconds\n"
     ]
    }
   ],
   "source": [
    "start3 = time.time()\n",
    "\n",
    "\n",
    "VGGmix = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGmix = VGGmix.to(device)\n",
    "VGGmix.make_layers()\n",
    "VGGmix._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGmix.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "seq_model_mix = get_seq_model(VGGmix)\n",
    "VGGmix = VGGmix.to(device)\n",
    "seq_model_mix = seq_model_mix.to(device)\n",
    "\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    " \"\"\"\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_mix = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_mix = netadapter_mix.reduce_net(seq_model_mix, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_mix, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "mid3 = time.time()\n",
    "print('Tempo di inizializzazione: {} minuti'.format((mid3 -start3)/60), flush=True)\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "print('Quello che segue  la accuracy del red_model_mix non ancora trainato usando train kd')\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mix(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item()\n",
    "        count += 1\n",
    "print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True) \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "optimizer_mix = torch.optim.Adam([{\n",
    "            'params': red_model_mix.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_mix.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_mix.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_mix, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_mix, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet_mix'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_mix,\n",
    "            VGGmix,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_mix,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_mix, device, test_loader))\n",
    "torch.save([red_model_mix.state_dict(), train_loss, test_loss], filename)\n",
    "\n",
    "end3 = time.time()\n",
    "time_VGGmix = end3 - start3\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mix(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() \n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "print('Tempo totale {:.1f} seconds'.format(time_VGGmix/60), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da una VGG non trainata e con red_model trainato per 60 epoche rispetto un teacher trainato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix = torch.Size([50000, 4096])\n",
      "Epoch 0 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 100 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 150 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 200 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 250 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 300 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 350 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 400 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 450 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Tempo di inizializzazione: 8.918427050113678 minuti\n",
      "Test Loss -4.807996464776993e-06\n",
      " Top 1:  Accuracy: 5154.0/50000 (10.31%)\n",
      "Test Loss: -0.24039982323884965\n",
      "Test Loss -2.4237807636260985e-05\n",
      " Top 1:  Accuracy: 1236.0/10000 (12.36%)\n",
      "Test Loss: -0.24237807636260986\n",
      "\n",
      "Loaded base model.\n",
      "\n",
      "EPOCH 1\n",
      "Train Loss kd: 3.1415343284606934e-05\n",
      "Test Loss -0.0003980171421813965\n",
      " Top 1:  Accuracy: 5695.0/10000 (56.95%)\n",
      "Test Loss: -3.980171421813965\n",
      "EPOCH 2\n",
      "Train Loss kd: 2.881650447845459e-05\n",
      "Test Loss -0.0005462036981201173\n",
      " Top 1:  Accuracy: 6273.0/10000 (62.73%)\n",
      "Test Loss: -5.462036981201172\n",
      "EPOCH 3\n",
      "Train Loss kd: 1.9977482557296753e-05\n",
      "Test Loss -0.0006725693194961548\n",
      " Top 1:  Accuracy: 6921.0/10000 (69.21%)\n",
      "Test Loss: -6.725693194961548\n",
      "EPOCH 4\n",
      "Train Loss kd: 1.978695511817932e-05\n",
      "Test Loss -0.0007542079581832886\n",
      " Top 1:  Accuracy: 7162.0/10000 (71.62%)\n",
      "Test Loss: -7.542079581832886\n",
      "EPOCH 5\n",
      "Train Loss kd: 6.3564175367355345e-06\n",
      "Test Loss -0.0008094702129364014\n",
      " Top 1:  Accuracy: 7261.0/10000 (72.61%)\n",
      "Test Loss: -8.094702129364014\n",
      "EPOCH 6\n",
      "Train Loss kd: 1.2153253555297852e-05\n",
      "Test Loss -0.0008191849464416505\n",
      " Top 1:  Accuracy: 7348.0/10000 (73.48%)\n",
      "Test Loss: -8.191849464416505\n",
      "EPOCH 7\n",
      "Train Loss kd: 1.4030933380126953e-05\n",
      "Test Loss -0.0009021330758285523\n",
      " Top 1:  Accuracy: 7475.0/10000 (74.75%)\n",
      "Test Loss: -9.021330758285522\n",
      "EPOCH 8\n",
      "Train Loss kd: 1.1513452529907227e-05\n",
      "Test Loss -0.0008774262858581543\n",
      " Top 1:  Accuracy: 7497.0/10000 (74.97%)\n",
      "Test Loss: -8.774262858581542\n",
      "EPOCH 9\n",
      "Train Loss kd: 2.363692820072174e-06\n",
      "Test Loss -0.0009229372645568847\n",
      " Top 1:  Accuracy: 7575.0/10000 (75.75%)\n",
      "Test Loss: -9.229372645568848\n",
      "EPOCH 10\n",
      "Train Loss kd: 4.483380019664765e-06\n",
      "Test Loss -0.0009216777280044555\n",
      " Top 1:  Accuracy: 7591.0/10000 (75.91%)\n",
      "Test Loss: -9.216777280044555\n",
      "EPOCH 11\n",
      "Train Loss kd: 5.522189140319825e-06\n",
      "Test Loss -0.0009518536405181885\n",
      " Top 1:  Accuracy: 7635.0/10000 (76.35%)\n",
      "Test Loss: -9.518536405181885\n",
      "EPOCH 12\n",
      "Train Loss kd: 2.086658328771591e-06\n",
      "Test Loss -0.0009926750920867921\n",
      " Top 1:  Accuracy: 7669.0/10000 (76.69%)\n",
      "Test Loss: -9.92675092086792\n",
      "EPOCH 13\n",
      "Train Loss kd: 1.0536994934082031e-05\n",
      "Test Loss -0.0010290584310531615\n",
      " Top 1:  Accuracy: 7742.0/10000 (77.42%)\n",
      "Test Loss: -10.290584310531615\n",
      "EPOCH 14\n",
      "Train Loss kd: 1.180591106414795e-05\n",
      "Test Loss -0.001029338553390503\n",
      " Top 1:  Accuracy: 7752.0/10000 (77.52%)\n",
      "Test Loss: -10.29338553390503\n",
      "EPOCH 15\n",
      "Train Loss kd: 6.366764307022095e-06\n",
      "Test Loss -0.00106520867313385\n",
      " Top 1:  Accuracy: 7752.0/10000 (77.52%)\n",
      "Test Loss: -10.652086731338501\n",
      "EPOCH 16\n",
      "Train Loss kd: 3.5675299167633057e-06\n",
      "Test Loss -0.0010543731632995604\n",
      " Top 1:  Accuracy: 7801.0/10000 (78.01%)\n",
      "Test Loss: -10.543731632995605\n",
      "EPOCH 17\n",
      "Train Loss kd: 1.2702033519744873e-05\n",
      "Test Loss -0.0010842759169769288\n",
      " Top 1:  Accuracy: 7757.0/10000 (77.57%)\n",
      "Test Loss: -10.842759169769288\n",
      "EPOCH 18\n",
      "Train Loss kd: 7.69933819770813e-06\n",
      "Test Loss -0.0010988529051208496\n",
      " Top 1:  Accuracy: 7817.0/10000 (78.17%)\n",
      "Test Loss: -10.988529051208497\n",
      "EPOCH 19\n",
      "Train Loss kd: 2.211484670639038e-05\n",
      "Test Loss -0.001076265234489441\n",
      " Top 1:  Accuracy: 7833.0/10000 (78.33%)\n",
      "Test Loss: -10.76265234489441\n",
      "EPOCH 20\n",
      "Train Loss kd: 1.1689814329147338e-05\n",
      "Test Loss -0.0010870315453338623\n",
      " Top 1:  Accuracy: 7872.0/10000 (78.72%)\n",
      "Test Loss: -10.870315453338623\n",
      "EPOCH 21\n",
      "Train Loss kd: 6.911840438842773e-06\n",
      "Test Loss -0.0011296855052566528\n",
      " Top 1:  Accuracy: 7852.0/10000 (78.52%)\n",
      "Test Loss: -11.296855052566528\n",
      "EPOCH 22\n",
      "Train Loss kd: 8.324578404426575e-06\n",
      "Test Loss -0.001112414017677307\n",
      " Top 1:  Accuracy: 7881.0/10000 (78.81%)\n",
      "Test Loss: -11.124140176773071\n",
      "EPOCH 23\n",
      "Train Loss kd: 2.5148102641105653e-06\n",
      "Test Loss -0.0011312047127151489\n",
      " Top 1:  Accuracy: 7898.0/10000 (78.98%)\n",
      "Test Loss: -11.312047127151489\n",
      "EPOCH 24\n",
      "Train Loss kd: 4.83206182718277e-06\n",
      "Test Loss -0.0011127632130813598\n",
      " Top 1:  Accuracy: 7944.0/10000 (79.44%)\n",
      "Test Loss: -11.127632130813598\n",
      "EPOCH 25\n",
      "Train Loss kd: 7.970631718635559e-06\n",
      "Test Loss -0.0011349428308105468\n",
      " Top 1:  Accuracy: 7913.0/10000 (79.13%)\n",
      "Test Loss: -11.349428308105468\n",
      "EPOCH 26\n",
      "Train Loss kd: 1.0301105678081512e-06\n",
      "Test Loss -0.0011536077925491332\n",
      " Top 1:  Accuracy: 7902.0/10000 (79.02%)\n",
      "Test Loss: -11.536077925491332\n",
      "EPOCH 27\n",
      "Train Loss kd: 1.748491644859314e-05\n",
      "Test Loss -0.001154868836555481\n",
      " Top 1:  Accuracy: 7954.0/10000 (79.54%)\n",
      "Test Loss: -11.54868836555481\n",
      "EPOCH 28\n",
      "Train Loss kd: 2.0918619632720945e-06\n",
      "Test Loss -0.0011630997792053221\n",
      " Top 1:  Accuracy: 7959.0/10000 (79.59%)\n",
      "Test Loss: -11.630997792053222\n",
      "EPOCH 29\n",
      "Train Loss kd: 8.745910525321961e-06\n",
      "Test Loss -0.0011756930858993532\n",
      " Top 1:  Accuracy: 7981.0/10000 (79.81%)\n",
      "Test Loss: -11.756930858993531\n",
      "EPOCH 30\n",
      "Train Loss kd: 7.3817729949951175e-06\n",
      "Test Loss -0.0011506117330551146\n",
      " Top 1:  Accuracy: 7975.0/10000 (79.75%)\n",
      "Test Loss: -11.506117330551147\n",
      "EPOCH 31\n",
      "Train Loss kd: 1.7750890254974365e-05\n",
      "Test Loss -0.0011539650367736816\n",
      " Top 1:  Accuracy: 7970.0/10000 (79.70%)\n",
      "Test Loss: -11.539650367736817\n",
      "EPOCH 32\n",
      "Train Loss kd: 2.7391925454139708e-06\n",
      "Test Loss -0.0011913297455215454\n",
      " Top 1:  Accuracy: 8019.0/10000 (80.19%)\n",
      "Test Loss: -11.913297455215455\n",
      "EPOCH 33\n",
      "Train Loss kd: 1.689422369003296e-05\n",
      "Test Loss -0.0012046998380661012\n",
      " Top 1:  Accuracy: 8044.0/10000 (80.44%)\n",
      "Test Loss: -12.04699838066101\n",
      "EPOCH 34\n",
      "Train Loss kd: 1.044774055480957e-05\n",
      "Test Loss -0.0011941853496551514\n",
      " Top 1:  Accuracy: 8003.0/10000 (80.03%)\n",
      "Test Loss: -11.941853496551513\n",
      "EPOCH 35\n",
      "Train Loss kd: 4.203849136829376e-06\n",
      "Test Loss -0.0012037285895156859\n",
      " Top 1:  Accuracy: 7944.0/10000 (79.44%)\n",
      "Test Loss: -12.03728589515686\n",
      "EPOCH 36\n",
      "Train Loss kd: 4.163663387298584e-06\n",
      "Test Loss -0.0012095819198608398\n",
      " Top 1:  Accuracy: 8007.0/10000 (80.07%)\n",
      "Test Loss: -12.095819198608398\n",
      "EPOCH 37\n",
      "Train Loss kd: 9.048567414283752e-06\n",
      "Test Loss -0.0011916175852584839\n",
      " Top 1:  Accuracy: 8008.0/10000 (80.08%)\n",
      "Test Loss: -11.91617585258484\n",
      "EPOCH 38\n",
      "Train Loss kd: 2.2775910794734956e-06\n",
      "Test Loss -0.001204183226661682\n",
      " Top 1:  Accuracy: 7998.0/10000 (79.98%)\n",
      "Test Loss: -12.04183226661682\n",
      "EPOCH 39\n",
      "Train Loss kd: 2.153716802597046e-05\n",
      "Test Loss -0.001218567717666626\n",
      " Top 1:  Accuracy: 8003.0/10000 (80.03%)\n",
      "Test Loss: -12.18567717666626\n",
      "EPOCH 40\n",
      "Train Loss kd: 1.3644256591796876e-05\n",
      "Test Loss -0.0012166563258743286\n",
      " Top 1:  Accuracy: 8030.0/10000 (80.30%)\n",
      "Test Loss: -12.166563258743286\n",
      "EPOCH 41\n",
      "Train Loss kd: 1.2887110710144044e-05\n",
      "Test Loss -0.0012095129733276368\n",
      " Top 1:  Accuracy: 8053.0/10000 (80.53%)\n",
      "Test Loss: -12.095129733276368\n",
      "EPOCH 42\n",
      "Train Loss kd: 3.591507077217102e-06\n",
      "Test Loss -0.00125313272857666\n",
      " Top 1:  Accuracy: 8013.0/10000 (80.13%)\n",
      "Test Loss: -12.5313272857666\n",
      "EPOCH 43\n",
      "Train Loss kd: 8.95585060119629e-06\n",
      "Test Loss -0.00126000623046875\n",
      " Top 1:  Accuracy: 8003.0/10000 (80.03%)\n",
      "Test Loss: -12.6000623046875\n",
      "EPOCH 44\n",
      "Train Loss kd: 8.771922588348389e-06\n",
      "Test Loss -0.0012196729694366455\n",
      " Top 1:  Accuracy: 8018.0/10000 (80.18%)\n",
      "Test Loss: -12.196729694366455\n",
      "EPOCH 45\n",
      "Train Loss kd: 2.5228378176689147e-06\n",
      "Test Loss -0.0012402045046997071\n",
      " Top 1:  Accuracy: 8086.0/10000 (80.86%)\n",
      "Test Loss: -12.40204504699707\n",
      "EPOCH 46\n",
      "Train Loss kd: 1.1982019245624542e-06\n",
      "Test Loss -0.0012429271895599365\n",
      " Top 1:  Accuracy: 8088.0/10000 (80.88%)\n",
      "Test Loss: -12.429271895599365\n",
      "EPOCH 47\n",
      "Train Loss kd: 1.7922703921794892e-06\n",
      "Test Loss -0.001249066381072998\n",
      " Top 1:  Accuracy: 8069.0/10000 (80.69%)\n",
      "Test Loss: -12.49066381072998\n",
      "EPOCH 48\n",
      "Train Loss kd: 1.1822478771209716e-05\n",
      "Test Loss -0.0012630859661865233\n",
      " Top 1:  Accuracy: 8067.0/10000 (80.67%)\n",
      "Test Loss: -12.630859661865234\n",
      "EPOCH 49\n",
      "Train Loss kd: 2.402058392763138e-06\n",
      "Test Loss -0.0012357076791381836\n",
      " Top 1:  Accuracy: 8089.0/10000 (80.89%)\n",
      "Test Loss: -12.357076791381836\n",
      "EPOCH 50\n",
      "Train Loss kd: 5.086093544960022e-06\n",
      "Test Loss -0.0012332340494537353\n",
      " Top 1:  Accuracy: 8117.0/10000 (81.17%)\n",
      "Test Loss: -12.332340494537354\n",
      "EPOCH 51\n",
      "Train Loss kd: 7.886335253715516e-06\n",
      "Test Loss -0.0012435021042251585\n",
      " Top 1:  Accuracy: 8079.0/10000 (80.79%)\n",
      "Test Loss: -12.435021042251586\n",
      "EPOCH 52\n",
      "Train Loss kd: 3.6600998044013975e-06\n",
      "Test Loss -0.0012756786961364746\n",
      " Top 1:  Accuracy: 8052.0/10000 (80.52%)\n",
      "Test Loss: -12.756786961364746\n",
      "EPOCH 53\n",
      "Train Loss kd: 1.0061700344085694e-05\n",
      "Test Loss -0.0012582312091064453\n",
      " Top 1:  Accuracy: 8095.0/10000 (80.95%)\n",
      "Test Loss: -12.582312091064454\n",
      "EPOCH 54\n",
      "Train Loss kd: 8.125704526901244e-06\n",
      "Test Loss -0.001298783786315918\n",
      " Top 1:  Accuracy: 8043.0/10000 (80.43%)\n",
      "Test Loss: -12.98783786315918\n",
      "EPOCH 55\n",
      "Train Loss kd: 5.603857040405274e-06\n",
      "Test Loss -0.001294277088317871\n",
      " Top 1:  Accuracy: 8073.0/10000 (80.73%)\n",
      "Test Loss: -12.94277088317871\n",
      "EPOCH 56\n",
      "Train Loss kd: 6.4618152379989625e-06\n",
      "Test Loss -0.0012863615036773682\n",
      " Top 1:  Accuracy: 8087.0/10000 (80.87%)\n",
      "Test Loss: -12.863615036773682\n",
      "EPOCH 57\n",
      "Train Loss kd: 1.0343484878540038e-05\n",
      "Test Loss -0.0012811366101455688\n",
      " Top 1:  Accuracy: 8109.0/10000 (81.09%)\n",
      "Test Loss: -12.811366101455688\n",
      "EPOCH 58\n",
      "Train Loss kd: 9.149393439292908e-07\n",
      "Test Loss -0.0012622486378479003\n",
      " Top 1:  Accuracy: 8111.0/10000 (81.11%)\n",
      "Test Loss: -12.622486378479003\n",
      "EPOCH 59\n",
      "Train Loss kd: 1.102465271949768e-05\n",
      "Test Loss -0.0012947460986328125\n",
      " Top 1:  Accuracy: 8111.0/10000 (81.11%)\n",
      "Test Loss: -12.947460986328124\n",
      "EPOCH 60\n",
      "Train Loss kd: 9.229175448417663e-06\n",
      "Test Loss -0.0012988486791229248\n",
      " Top 1:  Accuracy: 8105.0/10000 (81.05%)\n",
      "Test Loss: -12.988486791229247\n",
      "Accuracy of network on test images is 81.0500....count:1250\n",
      "5067.836964130402\n"
     ]
    }
   ],
   "source": [
    "start4 = time.time()\n",
    "\n",
    "\n",
    "VGGmixtrained = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "VGGmixtrained.make_layers()\n",
    "VGGmixtrained._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGmixtrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "seq_model_mixtrained = get_seq_model(VGGmixtrained)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "seq_model_mixtrained = seq_model_mixtrained.to(device)\n",
    "\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    " \"\"\"\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_mixtrained = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_mixtrained = netadapter_mixtrained.reduce_net(seq_model_mixtrained, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_mixtrained, flush=True)\n",
    "\n",
    "\n",
    "mid4 = time.time()\n",
    "print('Tempo di inizializzazione: {} minuti'.format((mid4 -start4)/60), flush=True)\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\"\"\" \n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "\n",
    "rednet_flops[0], rednet_flops[1], rednet_flops[2] = [\n",
    "    Total_flops(red_model.premodel, device),\n",
    "    Total_flops(red_model.proj_model, device),\n",
    "    Total_flops(red_model.inout_map, device)] \"\"\"\n",
    "\n",
    "\"\"\" total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "print('Quello che segue  la accuracy del red_model_mix non trainato usando train kd')\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mixtrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%50 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True) \"\"\"\n",
    "\n",
    "\n",
    "\"\"\" print(\n",
    "      'Pre nnz = {:.2f}, proj_model nnz={:.2f}, FNN nnz={:.4f}'.format(\n",
    "      rednet_storage[0], rednet_storage[1],\n",
    "      rednet_storage[2]), flush=True) \"\"\"\n",
    "\"\"\" print(\n",
    "      'flops:  Pre = {:.2f}, proj_model = {:.2f}, FNN ={:.2f}'.format(\n",
    "       rednet_flops[0], rednet_flops[1], rednet_flops[2]), flush=True) \"\"\"\n",
    "\n",
    "optimizer_mixtrained = torch.optim.Adam([{\n",
    "            'params': red_model_mixtrained.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_mixtrained, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet_mixtrained'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "VGGteacher = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "VGGteacher.make_layers()\n",
    "VGGteacher._initialize_weights()\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.SGD(VGGteacher.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGteacher, pretrained)\n",
    "seq_model_teacher = get_seq_model(VGGteacher)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "seq_model_teacher = seq_model_teacher.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_mixtrained,\n",
    "            VGGteacher,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_mixtrained,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "torch.save([red_model_mixtrained.state_dict(), train_loss, test_loss], filename)\n",
    "end4 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mixtrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() \n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "time_VGGmixtrained = end4 - start4\n",
    "print(time_VGGmixtrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
