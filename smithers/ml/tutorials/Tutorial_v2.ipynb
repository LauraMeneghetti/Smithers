{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 reduction tutorial\n",
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.utils import get_seq_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from smithers.ml.utils import randomized_range_finder\n",
    "from smithers.ml.utils import randomized_svd\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTING PROPER DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINIZIONE VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VGGnet = VGG(    cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGnet = VGGnet.to(device) #MODIF\n",
    "VGGnet.make_layers()\n",
    "VGGnet._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNZIONI PER IMPORT E EXPORT DEI MODELLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_torch(epoch, model, path, optimizer):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DEL DATASET CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8 #this can be changed\n",
    "data_path = '../datasets/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING (UNCOMMENT IF NO CHECKPOINT AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' print(\\'inizio training\\', flush=True)\\nprint(\\'Training iniziato\\') #MODIF\\nfor epoch in range(60):  # loop over the dataset multiple times\\n    print(\"Inizia ora l\\'epoca \"+str(epoch), flush=True)\\n    running_loss = 0.0\\n    for i, data in enumerate(train_loader, 0):\\n        # get the inputs; data is a list of [inputs, labels]\\n        inputs, labels = data\\n        inputs = inputs.to(device)\\n        labels = labels.to(device)\\n\\n\\n        # zero the parameter gradients\\n        optimizer.zero_grad()\\n\\n        # forward + backward + optimize\\n        outputs = VGGnet(inputs)\\n        outputs = outputs[1]\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        # print statistics\\n        running_loss += loss.item()\\n        #if i % 2000 == 1999:    # print every 2000 mini-batches\\n        if i % 200 == 199:    # print every 200 mini-batches #MODIF\\n            print(\\'[%d, %5d] loss: %.3f\\' %\\n                  (epoch + 1, i + 1, running_loss / 2000), flush=True)\\n            running_loss = 0.0\\n\\n\\n\\n\\nsave_checkpoint_torch(60, VGGnet, \\'/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_stefano.pth.tar\\', optimizer)\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" print('inizio training', flush=True)\n",
    "print('Training iniziato') #MODIF\n",
    "for epoch in range(60):  # loop over the dataset multiple times\n",
    "    print(\"Inizia ora l'epoca \"+str(epoch), flush=True)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = VGGnet(inputs)\n",
    "        outputs = outputs[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        if i % 200 == 199:    # print every 200 mini-batches #MODIF\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000), flush=True)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_checkpoint_torch(60, VGGnet, '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_stefano.pth.tar', optimizer)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING A CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "model = VGGnet\n",
    "load_checkpoint(model, pretrained)\n",
    "seq_model = get_seq_model(model)\n",
    "model = model.to(device) #MODIF\n",
    "seq_model = seq_model.to(device) #MODIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "VGGnet.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device))\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}'.format(100*correct/total), flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCTION OF VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on test images is 89.3333....count: 300\n",
      "Accuracy of network on test images is 89.0000....count: 600\n",
      "Accuracy of network on test images is 88.7917....count: 900\n",
      "Accuracy of network on test images is 88.8542....count: 1200\n",
      "Initializing reduction. Chosen reduction method is: RandSVD\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix (input di projection) = torch.Size([50000, 4096])\n",
      "si dovranno moltiplicare alcune righe di input_matrix per proj_matrix\n",
      "proj_mat è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "matrix è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "Comincia ora il training della FNN\n",
      "Epoch 0 of 500\n",
      "Epoch 50 of 500\n",
      "Epoch 100 of 500\n",
      "Epoch 150 of 500\n",
      "Epoch 200 of 500\n",
      "Epoch 250 of 500\n",
      "Epoch 300 of 500\n",
      "Epoch 350 of 500\n",
      "Epoch 400 of 500\n",
      "Epoch 450 of 500\n",
      "È terminato il training della rete neurale\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    "\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "#red_method = 'POD' \n",
    "red_method = 'RandSVD'\n",
    "inout_method = 'FNN'\n",
    "n_class = 10 #MODIF\n",
    "\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model = netadapter.reduce_net(seq_model, train_dataset, train_labels, train_loader, n_class).to(device) #MODIF\n",
    "print(red_model, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STORAGE AND FLOPS COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.6204e+00, 7.8125e-01, 4.6921e-03]) tensor([1.9051e+02, 2.0480e-01, 1.2000e-03])\n"
     ]
    }
   ],
   "source": [
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "\n",
    "rednet_flops[0], rednet_flops[1], rednet_flops[2] = [\n",
    "    Total_flops(red_model.premodel, device),\n",
    "    Total_flops(red_model.proj_model, device),\n",
    "    Total_flops(red_model.inout_map, device)]\n",
    "print(rednet_storage, rednet_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%50 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    "\n",
    "\n",
    "print(\n",
    "      'Pre nnz = {:.2f}, proj_model nnz={:.2f}, FNN nnz={:.4f}'.format(\n",
    "      rednet_storage[0], rednet_storage[1],\n",
    "      rednet_storage[2]), flush=True)\n",
    "print(\n",
    "      'flops:  Pre = {:.2f}, proj_model = {:.2f}, FNN ={:.2f}'.format(\n",
    "       rednet_flops[0], rednet_flops[1], rednet_flops[2]), flush=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([{\n",
    "            'params': red_model.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 10\n",
    "filename = './cifar10_VGG16_RedNet'+red_method+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "\"\"\" if os.path.isfile(filename):\n",
    "    [rednet_pretrained, train_loss,test_loss] = torch.load(filename)\n",
    "    red_model.load_state_dict(rednet_pretrained)\n",
    "    print('rednet trained {} epoches is loaded'.format(epochs), flush=True)\n",
    "else:\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_loss.append(compute_loss(red_model, device, train_loader))\n",
    "    test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print('EPOCH {}'.format(epoch), flush=True)\n",
    "        train_loss.append(\n",
    "                train_kd(red_model,\n",
    "                model,\n",
    "                device,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                train_max_batch=200,\n",
    "                alpha=0.1,\n",
    "                temperature=1.,\n",
    "                epoch=epoch))\n",
    "        test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "    torch.save([red_model.state_dict(), train_loss, test_loss], filename) \"\"\"\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model,\n",
    "            model,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "torch.save([red_model.state_dict(), train_loss, test_loss], filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3) \"\"\"\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "rednet_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\"\"\"\n",
    "\n",
    "rednet_storage_VGG = torch.zeros(1)\n",
    "\n",
    "rednet_storage_VGG[0] = Total_param(VGGnet)\n",
    "rednet_storage_VGG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
