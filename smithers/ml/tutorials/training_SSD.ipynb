{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training SSD300 (tutorial)\n",
    "In this tutorial, we will show how to initialize, train and test SSD300 for object detection.\n",
    "The tutorial is based on a subset of pictures from the PascalVOC dataset (both 2007 and 2012), but can be generalized to be used with the whole PascalVOC or other custom/benchmark datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "We start by importing all the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/scratch/lmeneghe/Smithers/')\n",
    "\n",
    "from smithers.ml.models.vgg import VGG\n",
    "from smithers.ml.models.aux_conv import AuxiliaryConvolutions\n",
    "from smithers.ml.models.predictor import PredictionConvolutions\n",
    "from smithers.ml.dataset.pascalvoc_dataset import PascalVOCDataset\n",
    "from smithers.ml.models.detector import Detector\n",
    "from smithers.ml.models.utils_objdet import create_prior_boxes\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters Initialization\n",
    "We set the parameters used for the data, the detector and the learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "batch_size = 8  # batch size\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "iterations = 120000  # number of iterations to train\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1\n",
    "# decay learning rate to this fraction of the existing learning rate\n",
    "#n_classes = 6\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None\n",
    "# clip if gradients are exploding, which may happen at larger batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "We need to load and create the datasets for training and testing our model. In this case we are using a dataset extracted from PascalVOC that has been created using ***smithers/ml/dataset/sample_dataset.py***. For more details about this, refer to the tutorial ***pascalvoc_preparation***, which explains also how to use the whole PascalVOC dataset. Instead, to use a custom dataset for this purpose, refer to the turial ***customdata_objdet***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: {'cat': 1, 'dog': 2, 'background': 0}\n",
      "n_classes: 3\n",
      "Training images: 240\n",
      "Testing images: 60\n"
     ]
    }
   ],
   "source": [
    "#voc_labels = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "#        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "#        'cow', 'diningtable', 'dog', 'horse',\n",
    "#        'motorbike', 'person', 'pottedplant',\n",
    "#        'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "voc_labels = ('cat', 'dog')\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "n_classes = len(label_map)\n",
    "print('categories:',label_map)\n",
    "print('n_classes:', n_classes)\n",
    "\n",
    "# Data parameters\n",
    "data_folder = 'VOC_dog_cat/JSONfiles' #folder with json data files\n",
    "keep_difficult = True\n",
    "\n",
    "\n",
    "train_dataset = PascalVOCDataset(data_folder,\n",
    "                                 split='train',\n",
    "                                 keep_difficult=keep_difficult)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "epochs = iterations // (len(train_dataset) // 16) #500\n",
    "decay_lr_at = [it // (len(train_dataset) // 16) for it in decay_lr_at]\n",
    "print('Training images:', len(train_dataset))\n",
    "\n",
    "\n",
    "test_dataset = PascalVOCDataset(data_folder,\n",
    "                                split='test',\n",
    "                                keep_difficult=keep_difficult)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          collate_fn=test_dataset.collate_fn,\n",
    "                                          num_workers=workers,\n",
    "                                          pin_memory=True)\n",
    "print('Testing images:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation and loading of the SSD300 model\n",
    "We are now going to initialize SSD300 using the class ***Detector*** of ***smithers/ml/models/detector.py***, based on the original paper: \n",
    "\n",
    "'SSD: Single Shot Multibox Detector' by Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg https://arxiv.org/abs/1512.02325 ,DOI: 10.1007/978-3-319-46448-0_2\n",
    "\n",
    "In this case, we should select 'ssd' as classifier for VGG in order to substitute the feedforward classification layers of the original VGG with convolutional layers. We have then initialized SSD300 using pre-trained wegiths on ImageNet (a common choice in this field).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Time needed to initialize the net: 2.57 seconds\n"
     ]
    }
   ],
   "source": [
    "start_init = time()\n",
    "base_net = VGG(classifier='ssd', init_weights='imagenet')\n",
    "aux_conv = AuxiliaryConvolutions()\n",
    "predictor = PredictionConvolutions(n_classes)\n",
    "network = [base_net, aux_conv, predictor]\n",
    "priors_cxcy = create_prior_boxes()\n",
    "end_init = time()\n",
    "print('Time needed to initialize the net: {} seconds'.format(round(end_init-start_init,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase\n",
    "Once we have created and initliazed the network we can train it.\n",
    "\n",
    "\n",
    "Here, the network will trained and, if provided, a checkpoint can be used to start from an already trained network.\n",
    "\n",
    "The training procedure will store a checkpoint file named ``checkpoint_ssd300.pth.tar``, once it is completed.\n",
    "Furthermore, the plot of the value of the loss against the corresponding epoch is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = None # if no checkpoint available\n",
    "#check = 'checkpoint_ssd300.pth.tar' #if a checkpoint is available\n",
    "epochs = 15\n",
    "start = time()\n",
    "detector = Detector(network, check, priors_cxcy, n_classes, epochs,\n",
    "                        batch_size, print_freq, lr, decay_lr_at,\n",
    "                        decay_lr_to, momentum, weight_decay, grad_clip,\n",
    "                        train_loader, test_loader)\n",
    "print(detector.model)\n",
    "checkpoint, loss_values, mAP_values = detector.train_detector_with_eval(label_map)\n",
    "end = time()\n",
    "print(f'Time needed for training the net: {round(end-start,2)} seconds, i.e. {round((end-start)/60,1)} minutes')\n",
    "start_test = time()\n",
    "epo = np.arange(start=0, stop=epochs, step=1)\n",
    "plt.plot(epo, loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value Loss')\n",
    "plt.savefig('loss_pascal_cat.png')\n",
    "detector.eval_detector(label_map, checkpoint)\n",
    "end_test = time()\n",
    "\n",
    "print(f'Time needed for testing the net: {round(end_test-start_test,2)} seconds, i.e. {round((end_test-start_test)/60,1)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING WITH AN IMAGE + PRINT\n",
    "By choosing a specific image from the directory used, the network is able to detect the object(s) in it and save a version of the image in which the bounding box(es) with the relative label(s) is(/are) pictured. To view this, open the file ``out.jpg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/001239.jpg'\n",
    "#img_path = 'voc_dir/VOC_cat-dog/JPEGImages/001239.jpg'\n",
    "original_image = Image.open(img_path, mode='r')\n",
    "original_image = original_image.convert('RGB')\n",
    "\n",
    "detector.detect(original_image,\n",
    "                checkpoint,\n",
    "                label_map,\n",
    "                min_score=0.01,\n",
    "                max_overlap=0.45,\n",
    "                top_k=3).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
