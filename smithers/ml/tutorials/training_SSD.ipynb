{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD TRAINING AND TESTING (TUTORIAL)\n",
    "In this tutorial, we will show how to initialize, train and test an SSD300 for object detection.\n",
    "The tutorial is based on a subset of pictures from the PascalVOC dataset (both 2007 and 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS\n",
    "We start by importing all the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.models.aux_conv import AuxiliaryConvolutions\n",
    "from smithers.ml.models.predictor import PredictionConvolutions\n",
    "from smithers.ml.dataset.pascalvoc_dataset import PascalVOCDataset\n",
    "from smithers.ml.models.detector import Detector\n",
    "from smithers.ml.models.utils import create_prior_boxes\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNING PARAMETERS\n",
    "Then, we set the parameters used for the data, the detector and the learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: {'cat': 1, 'dog': 2, 'background': 0}\n",
      "n_classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Learning parameters\n",
    "batch_size = 8  # batch size\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "iterations = 120000  # number of iterations to train\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1\n",
    "# decay learning rate to this fraction of the existing learning rate\n",
    "#n_classes = 6\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None\n",
    "# clip if gradients are exploding, which may happen at larger batch sizes\n",
    "\n",
    "#voc_labels = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "#        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "#        'cow', 'diningtable', 'dog', 'horse',\n",
    "#        'motorbike', 'person', 'pottedplant',\n",
    "#        'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "voc_labels = ('cat', 'dog')\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "n_classes = len(label_map)\n",
    "print('categories:',label_map)\n",
    "print('n_classes:', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PARAMETERS\n",
    "We now define the train and test images, after they have been extracted and the subdivision has been carried out (refer to the data preparation tutorial for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 240\n",
      "Testing images: 60\n"
     ]
    }
   ],
   "source": [
    "# Data parameters\n",
    "data_folder = 'VOC_dog_cat/JSONfiles' #folder with json data files\n",
    "keep_difficult = True\n",
    "\n",
    "\n",
    "train_dataset = PascalVOCDataset(data_folder,\n",
    "                                 split='train',\n",
    "                                 keep_difficult=keep_difficult)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "epochs = iterations // (len(train_dataset) // 16) #500\n",
    "decay_lr_at = [it // (len(train_dataset) // 16) for it in decay_lr_at]\n",
    "print('Training images:', len(train_dataset))\n",
    "\n",
    "\n",
    "test_dataset = PascalVOCDataset(data_folder,\n",
    "                                split='test',\n",
    "                                keep_difficult=keep_difficult)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          collate_fn=test_dataset.collate_fn,\n",
    "                                          num_workers=workers,\n",
    "                                          pin_memory=True)\n",
    "print('Testing images:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK INITIALIZATION\n",
    "The following cell contains the lines used to instantiate the detector object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Time needed to initialize the net: 1.79 seconds\n"
     ]
    }
   ],
   "source": [
    "start_init = time()\n",
    "base_net = VGG(classifier='ssd', init_weights=False)\n",
    "aux_conv = AuxiliaryConvolutions()\n",
    "predictor = PredictionConvolutions(n_classes)\n",
    "network = [base_net, aux_conv, predictor]\n",
    "priors_cxcy = create_prior_boxes()\n",
    "end_init = time()\n",
    "print(f'Time needed to initialize the net: {round(end_init-start_init,2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK TRAINING/LOADING A CHECKPOINT, TESTING THE NETWORK\n",
    "Here, the network will trained and, if provided, a checkpoint can be used to start from an already trained network.\n",
    "It is possible to choose a different number for the ``epochs`` variable (obviously, choosing a low number will not produce satisfactory results).\n",
    "The cell also prints the time spans needed to perform some operations and prints the final model, moreover pieces of information specific to the different epochs are generated at each iteration.\n",
    "\n",
    "The training procedure will store a checkpoint file named ``checkpoint_ssd300.pth.tar``, once it is completed.\n",
    "Furthermore, the plot of the value of the loss against the corresponding epoch is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "), AuxiliaryConvolutions(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "), PredictionConvolutions(\n",
      "  (features_loc): Sequential(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (features_cl): Sequential(\n",
      "    (0): Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")]\n",
      "Training (with evaluation) has started.\n",
      "Epoch: [0][0/30]\tBatch Time 1.621 (1.621)\tData Time 0.349 (0.349)\tLoss 79.7379 (79.7379)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.000\n",
      "Epoch: [1][0/30]\tBatch Time 0.541 (0.541)\tData Time 0.291 (0.291)\tLoss 7.0549 (7.0549)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.000\n",
      "Epoch: [2][0/30]\tBatch Time 0.534 (0.534)\tData Time 0.305 (0.305)\tLoss 5.1991 (5.1991)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.142\n",
      "Epoch: [3][0/30]\tBatch Time 0.545 (0.545)\tData Time 0.316 (0.316)\tLoss 4.1738 (4.1738)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.101\n",
      "Epoch: [4][0/30]\tBatch Time 0.488 (0.488)\tData Time 0.279 (0.279)\tLoss 3.6975 (3.6975)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.091\n",
      "Epoch: [5][0/30]\tBatch Time 0.475 (0.475)\tData Time 0.248 (0.248)\tLoss 2.8406 (2.8406)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.183\n",
      "Epoch: [6][0/30]\tBatch Time 0.545 (0.545)\tData Time 0.336 (0.336)\tLoss 4.5952 (4.5952)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.130\n",
      "Epoch: [7][0/30]\tBatch Time 0.651 (0.651)\tData Time 0.419 (0.419)\tLoss 6.5763 (6.5763)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.173\n",
      "Epoch: [8][0/30]\tBatch Time 0.576 (0.576)\tData Time 0.346 (0.346)\tLoss 4.1193 (4.1193)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.157\n",
      "Epoch: [9][0/30]\tBatch Time 0.543 (0.543)\tData Time 0.331 (0.331)\tLoss 5.6707 (5.6707)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.216\n",
      "Epoch: [10][0/30]\tBatch Time 0.529 (0.529)\tData Time 0.317 (0.317)\tLoss 3.7730 (3.7730)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.198\n",
      "Epoch: [11][0/30]\tBatch Time 0.585 (0.585)\tData Time 0.374 (0.374)\tLoss 4.4251 (4.4251)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.231\n",
      "Epoch: [12][0/30]\tBatch Time 0.516 (0.516)\tData Time 0.304 (0.304)\tLoss 3.3412 (3.3412)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.178\n",
      "Epoch: [13][0/30]\tBatch Time 0.518 (0.518)\tData Time 0.306 (0.306)\tLoss 4.9013 (4.9013)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.248\n",
      "Epoch: [14][0/30]\tBatch Time 0.455 (0.455)\tData Time 0.243 (0.243)\tLoss 3.6686 (3.6686)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.112\n",
      "Training (with evaluation) is now complete.\n",
      "Time needed for training the net: 204.72 seconds, i.e. 3.4 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 0.09745939821004868, 'dog': 0.12730325758457184}\n",
      "{'cat': 0.09745939821004868, 'dog': 0.12730325758457184}\n",
      "\n",
      "Mean Average Precision (mAP): 0.112\n",
      "Time needed for testing the net: 10.63 seconds, i.e. 0.2 minutes\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check = None # if no checkpoint available\n",
    "#check = 'checkpoint_ssd300.pth.tar' #if a checkpoint is available\n",
    "#check = 'Results/2000_full/checkpoint_ssd300.pth.tar'\n",
    "epochs = 15\n",
    "start = time()\n",
    "detector = Detector(network, check, priors_cxcy, n_classes, epochs,\n",
    "                        batch_size, print_freq, lr, decay_lr_at,\n",
    "                        decay_lr_to, momentum, weight_decay, grad_clip,\n",
    "                        train_loader, test_loader)\n",
    "print(detector.model)\n",
    "checkpoint, loss_values, mAP_values = detector.train_detector_with_eval(label_map)\n",
    "end = time()\n",
    "print(f'Time needed for training the net: {round(end-start,2)} seconds, i.e. {round((end-start)/60,1)} minutes')\n",
    "start_test = time()\n",
    "epo = np.arange(start=0, stop=epochs, step=1)\n",
    "plt.plot(epo, loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value Loss')\n",
    "plt.savefig('loss_pascal_cat.png')\n",
    "detector.eval_detector(label_map, checkpoint)\n",
    "end_test = time()\n",
    "\n",
    "print(f'Time needed for testing the net: {round(end_test-start_test,2)} seconds, i.e. {round((end_test-start_test)/60,1)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING WITH AN IMAGE + PRINT\n",
    "By choosing a specific image from the directory used, the network is able to detect the object(s) in it and save a version of the image in which the bounding box(es) with the relative label(s) is(/are) pictured. To view this, open the file ``out.jpg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/001239.jpg'\n",
    "#img_path = 'voc_dir/VOC_cat-dog/JPEGImages/001239.jpg'\n",
    "original_image = Image.open(img_path, mode='r')\n",
    "original_image = original_image.convert('RGB')\n",
    "\n",
    "detector.detect(original_image,\n",
    "                checkpoint,\n",
    "                label_map,\n",
    "                min_score=0.01,\n",
    "                max_overlap=0.45,\n",
    "                top_k=3).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
