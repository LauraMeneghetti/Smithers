{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD TRAINING AND TESTING (TUTORIAL)\n",
    "In this tutorial, we will show how to initialize, train and test an SSD300 for object detection.\n",
    "The tutorial is based on a subset of pictures from the PascalVOC dataset (both 2007 and 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS\n",
    "We start by importing all the necessary functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.models.aux_conv import AuxiliaryConvolutions\n",
    "from smithers.ml.models.predictor import PredictionConvolutions\n",
    "from smithers.ml.dataset.pascalvoc_dataset import PascalVOCDataset\n",
    "from smithers.ml.models.detector import Detector\n",
    "from smithers.ml.models.utils import create_prior_boxes\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEARNING PARAMETERS\n",
    "Then, we set the parameters used for the data, the detector and the learning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: {'cat': 1, 'dog': 2, 'background': 0}\n",
      "n_classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Learning parameters\n",
    "batch_size = 8  # batch size\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "iterations = 120000  # number of iterations to train\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1\n",
    "# decay learning rate to this fraction of the existing learning rate\n",
    "#n_classes = 6\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None\n",
    "# clip if gradients are exploding, which may happen at larger batch sizes\n",
    "\n",
    "#voc_labels = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "#        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "#        'cow', 'diningtable', 'dog', 'horse',\n",
    "#        'motorbike', 'person', 'pottedplant',\n",
    "#        'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "voc_labels = ('cat', 'dog')\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "n_classes = len(label_map)\n",
    "print('categories:',label_map)\n",
    "print('n_classes:', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PARAMETERS\n",
    "We now define the train and test images, after they have been extracted and the subdivision has been carried out (refer to the data preparation tutorial for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 240\n",
      "Testing images: 60\n"
     ]
    }
   ],
   "source": [
    "# Data parameters\n",
    "data_folder = 'VOC_dog_cat/JSONfiles' #folder with json data files\n",
    "keep_difficult = True\n",
    "\n",
    "\n",
    "train_dataset = PascalVOCDataset(data_folder,\n",
    "                                 split='train',\n",
    "                                 keep_difficult=keep_difficult)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "epochs = iterations // (len(train_dataset) // 16) #500\n",
    "decay_lr_at = [it // (len(train_dataset) // 16) for it in decay_lr_at]\n",
    "print('Training images:', len(train_dataset))\n",
    "\n",
    "\n",
    "test_dataset = PascalVOCDataset(data_folder,\n",
    "                                split='test',\n",
    "                                keep_difficult=keep_difficult)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          collate_fn=test_dataset.collate_fn,\n",
    "                                          num_workers=workers,\n",
    "                                          pin_memory=True)\n",
    "print('Testing images:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK INITIALIZATION\n",
    "The following cell contains the lines used to instantiate the detector object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Time needed to initialize the net: 1.77 seconds\n"
     ]
    }
   ],
   "source": [
    "start_init = time()\n",
    "base_net = VGG(classifier='ssd', init_weights=False)\n",
    "aux_conv = AuxiliaryConvolutions()\n",
    "predictor = PredictionConvolutions(n_classes)\n",
    "network = [base_net, aux_conv, predictor]\n",
    "priors_cxcy = create_prior_boxes()\n",
    "end_init = time()\n",
    "print(f'Time needed to initialize the net: {round(end_init-start_init,2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NETWORK TRAINING/LOADING A CHECKPOINT, TESTING THE NETWORK\n",
    "Here, the network will trained and, if provided, a checkpoint can be used to start from an already trained network.\n",
    "It is possible to choose a different number for the ``epochs`` variable (obviously, choosing a low number will not produce satisfactory results).\n",
    "The cell also prints the time spans needed to perform some operations and prints the final model, moreover pieces of information specific to the different epochs are generated at each iteration.\n",
    "\n",
    "The training procedure will store a checkpoint file named ``checkpoint_ssd300.pth.tar``, once it is completed.\n",
    "Furthermore, the plot of the value of the loss against the corresponding epoch is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint from epoch 2000.\n",
      "\n",
      "[VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "), AuxiliaryConvolutions(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "), PredictionConvolutions(\n",
      "  (features_loc): Sequential(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (features_cl): Sequential(\n",
      "    (0): Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")]\n",
      "Training (with evaluation) has started.\n",
      "Epoch: [2000][0/30]\tBatch Time 1.494 (1.494)\tData Time 0.391 (0.391)\tLoss 1.0543 (1.0543)\t\n",
      "\n",
      "Mean Average Precision (mAP): 0.690\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb Cella 11\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m detector \u001b[39m=\u001b[39m Detector(network, checkpoint, priors_cxcy, n_classes, epochs,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m                         batch_size, print_freq, lr, decay_lr_at,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                         decay_lr_to, momentum, weight_decay, grad_clip,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                         train_loader, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(detector\u001b[39m.\u001b[39mmodel)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m checkpoint, loss_values, mAP_values \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mtrain_detector_with_eval(label_map)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCHECKPOINT: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m- type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(checkpoint)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m- Name: \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/training_SSD.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m end \u001b[39m=\u001b[39m time()\n",
      "File \u001b[0;32m~/Smithers/smithers/ml/models/detector.py:319\u001b[0m, in \u001b[0;36mDetector.train_detector_with_eval\u001b[0;34m(self, label_map)\u001b[0m\n\u001b[1;32m    317\u001b[0m     mAP_values\u001b[39m.\u001b[39mextend([\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_current_detector(label_map)]) \u001b[39m##MODIF\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39mif\u001b[39;00m epoch\u001b[39m%\u001b[39m\u001b[39m500\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m##MODIF\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m         place_holder \u001b[39m=\u001b[39m save_checkpoint_objdet(epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, with_epochs \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mYes\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m##MODIF\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39m# Save checkpoint\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining (with evaluation) is now complete.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Smithers/smithers/ml/models/utils.py:677\u001b[0m, in \u001b[0;36msave_checkpoint_objdet\u001b[0;34m(epoch, model, optimizer, cut_idx, with_epochs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcheckpoint_VGG16_ASNet_sparse_cutID_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.pth.tar\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (cut_idx)\n\u001b[0;32m--> 677\u001b[0m torch\u001b[39m.\u001b[39;49msave(state, filename)\n\u001b[1;32m    678\u001b[0m \u001b[39mreturn\u001b[39;00m filename\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/torch/serialization.py:214\u001b[0m, in \u001b[0;36m_open_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#checkpoint = None # if no checkpoint available\n",
    "#checkpoint = 'checkpoint_ssd300.pth.tar' #if a checkpoint is available\n",
    "checkpoint = 'Results/2000 ep full/checkpoint_ssd300.pth.tar'\n",
    "epochs = 20\n",
    "start = time()\n",
    "detector = Detector(network, checkpoint, priors_cxcy, n_classes, epochs,\n",
    "                        batch_size, print_freq, lr, decay_lr_at,\n",
    "                        decay_lr_to, momentum, weight_decay, grad_clip,\n",
    "                        train_loader, test_loader)\n",
    "print(detector.model)\n",
    "checkpoint, loss_values, mAP_values = detector.train_detector_with_eval(label_map)\n",
    "print(f'CHECKPOINT: \\n- type: {type(checkpoint)}\\n- Name: {checkpoint}')\n",
    "end = time()\n",
    "print(f'Time needed for training the net: {round(end-start,2)} seconds, i.e. {round((end-start)/60,1)} minutes')\n",
    "start_test = time()\n",
    "epo = np.arange(start=0, stop=epochs, step=1)\n",
    "plt.plot(epo, loss_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Value Loss')\n",
    "plt.savefig('loss_pascal_cat.png')\n",
    "detector.eval_detector(label_map, checkpoint)\n",
    "end_test = time()\n",
    "\n",
    "print(f'Time needed for testing the net: {round(end_test-start_test,2)} seconds, i.e. {round((end_test-start_test)/60,1)} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING WITH AN IMAGE + PRINT\n",
    "By choosing a specific image from the directory used, the network is able to detect the object(s) in it and save a version of the image in which the bounding box(es) with the relative label(s) is(/are) pictured. To view this, open the file ``out.jpg``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/002215.jpg'\n",
    "#img_path = 'voc_dir/VOC_cat-dog/JPEGImages/000122.jpg'\n",
    "original_image = Image.open(img_path, mode='r')\n",
    "original_image = original_image.convert('RGB')\n",
    "\n",
    "detector.detect(original_image,\n",
    "                checkpoint,\n",
    "                label_map,\n",
    "                min_score=0.01,\n",
    "                max_overlap=0.45,\n",
    "                top_k=5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
