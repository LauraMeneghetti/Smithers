{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.utils import get_seq_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8 #this can be changed\n",
    "data_path = '../datasets/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint_torch(epoch, model, path, optimizer):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire dalla VGG trainata dal checkpoint e con red_model trainato con train_kd (red_method = 'POD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix = torch.Size([50000, 4096])\n",
      "Epoch 0 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 50 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 100 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 150 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 200 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 250 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 300 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 350 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 400 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 450 of 500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "L'inizializzazione ha impiegato 8.8 minuti\n",
      "Test Loss 0.00017220988927002547\n",
      " Top 1:  Accuracy: 6498.0/50000 (13.00%)\n",
      "Test Loss: 8.610494463501274\n",
      "Test Loss 0.0009103378942966462\n",
      " Top 1:  Accuracy: 1275.0/10000 (12.75%)\n",
      "Test Loss: 9.103378942966462\n",
      "EPOCH 1\n",
      "Train Loss kd: 9.212216138839722e-06\n",
      "Test Loss -0.0006444106830120087\n",
      " Top 1:  Accuracy: 8411.0/10000 (84.11%)\n",
      "Test Loss: -6.444106830120087\n",
      "EPOCH 2\n",
      "Train Loss kd: 2.5716087222099305e-06\n",
      "Test Loss -0.0007834380321788788\n",
      " Top 1:  Accuracy: 8649.0/10000 (86.49%)\n",
      "Test Loss: -7.834380321788788\n",
      "EPOCH 3\n",
      "Train Loss kd: 1.3555024862289429e-05\n",
      "Test Loss -0.0008292321416616441\n",
      " Top 1:  Accuracy: 8781.0/10000 (87.81%)\n",
      "Test Loss: -8.29232141661644\n",
      "EPOCH 4\n",
      "Train Loss kd: 1.7814967781305312e-07\n",
      "Test Loss -0.0009113735525274277\n",
      " Top 1:  Accuracy: 8853.0/10000 (88.53%)\n",
      "Test Loss: -9.113735525274278\n",
      "EPOCH 5\n",
      "Train Loss kd: 6.683323979377747e-06\n",
      "Test Loss -0.0009809486155700684\n",
      " Top 1:  Accuracy: 8852.0/10000 (88.52%)\n",
      "Test Loss: -9.809486155700684\n",
      "EPOCH 6\n",
      "Train Loss kd: 9.97372344136238e-07\n",
      "Test Loss -0.0010012650233078002\n",
      " Top 1:  Accuracy: 8868.0/10000 (88.68%)\n",
      "Test Loss: -10.012650233078002\n",
      "EPOCH 7\n",
      "Train Loss kd: 3.524695336818695e-07\n",
      "Test Loss -0.001032712427930832\n",
      " Top 1:  Accuracy: 8916.0/10000 (89.16%)\n",
      "Test Loss: -10.327124279308318\n",
      "EPOCH 8\n",
      "Train Loss kd: 1.9785167276859285e-06\n",
      "Test Loss -0.0010224991795635223\n",
      " Top 1:  Accuracy: 8898.0/10000 (88.98%)\n",
      "Test Loss: -10.224991795635223\n",
      "EPOCH 9\n",
      "Train Loss kd: 1.8968021497130393e-07\n",
      "Test Loss -0.0010713501422595978\n",
      " Top 1:  Accuracy: 8945.0/10000 (89.45%)\n",
      "Test Loss: -10.713501422595979\n",
      "EPOCH 10\n",
      "Train Loss kd: 4.551142454147339e-07\n",
      "Test Loss -0.0011109929700279238\n",
      " Top 1:  Accuracy: 8922.0/10000 (89.22%)\n",
      "Test Loss: -11.109929700279237\n",
      "Accuracy of network on test images is 89.2200....count:1250\n",
      "This took 21.4 minutes\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "\n",
    "\n",
    "VGGcomplete = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "VGGcomplete.make_layers()\n",
    "VGGcomplete._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGcomplete.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGcomplete, pretrained)\n",
    "seq_model_complete = get_seq_model(VGGcomplete)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "seq_model_complete = seq_model_complete.to(device)\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_complete = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_complete = netadapter_complete.reduce_net(seq_model_complete, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_complete, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "mid1 = time.time()\n",
    "print(\"L'inizializzazione ha impiegato {:.1f} minuti\".format((mid1-start1)/60))\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "\n",
    "optimizer_complete = torch.optim.Adam([{\n",
    "            'params': red_model_complete.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_complete.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_complete.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_complete, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 10\n",
    "filename = './cifar10_VGG16_RedNet_complete'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_complete,\n",
    "            VGGcomplete,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_complete,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "torch.save([red_model_complete.state_dict(), train_loss, test_loss], filename)\n",
    "end1 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_complete(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "time_VGGcomplete = end1 - start1\n",
    "print('This took {:.1f} minutes'.format(time_VGGcomplete/60), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire dalla VGG trainata dal checkpoint e con red_model trainato con train_kd (red_method = 'RandSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: RandSVD\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix (input di projection) = torch.Size([50000, 4096])\n",
      "si dovranno moltiplicare alcune righe di input_matrix per proj_matrix\n",
      "proj_mat è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "matrix è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "Comincia ora il training della FNN\n",
      "Epoch 0 of 500\n",
      "Epoch 50 of 500\n",
      "Epoch 100 of 500\n",
      "Epoch 150 of 500\n",
      "Epoch 200 of 500\n",
      "Epoch 250 of 500\n",
      "Epoch 300 of 500\n",
      "Epoch 350 of 500\n",
      "Epoch 400 of 500\n",
      "Epoch 450 of 500\n",
      "È terminato il training della rete neurale\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "L'inizializzazione ha impiegato 8.7 minuti\n",
      "Test Loss 5.881644647194445e-05\n",
      " Top 1:  Accuracy: 4696.0/50000 (9.39%)\n",
      "Test Loss: 2.9408223235972226\n",
      "Test Loss 0.0002984974394619465\n",
      " Top 1:  Accuracy: 883.0/10000 (8.83%)\n",
      "Test Loss: 2.984974394619465\n",
      "EPOCH 1\n",
      "Train Loss kd: 1.5547951459884643e-05\n",
      "Test Loss -0.0008788150361251832\n",
      " Top 1:  Accuracy: 8238.0/10000 (82.38%)\n",
      "Test Loss: -8.788150361251832\n",
      "EPOCH 2\n",
      "Train Loss kd: 6.410084199160337e-08\n",
      "Test Loss -0.0010203249759101866\n",
      " Top 1:  Accuracy: 8695.0/10000 (86.95%)\n",
      "Test Loss: -10.203249759101867\n",
      "EPOCH 3\n",
      "Train Loss kd: 9.05693843960762e-07\n",
      "Test Loss -0.0011433616449737548\n",
      " Top 1:  Accuracy: 8774.0/10000 (87.74%)\n",
      "Test Loss: -11.43361644973755\n",
      "EPOCH 4\n",
      "Train Loss kd: 3.2823864370584487e-07\n",
      "Test Loss -0.0012379039219665526\n",
      " Top 1:  Accuracy: 8801.0/10000 (88.01%)\n",
      "Test Loss: -12.379039219665527\n",
      "EPOCH 5\n",
      "Train Loss kd: 3.581041693687439e-06\n",
      "Test Loss -0.0013131494703674316\n",
      " Top 1:  Accuracy: 8855.0/10000 (88.55%)\n",
      "Test Loss: -13.131494703674317\n",
      "EPOCH 6\n",
      "Train Loss kd: 1.1630455404520034e-06\n",
      "Test Loss -0.0013434820737457276\n",
      " Top 1:  Accuracy: 8876.0/10000 (88.76%)\n",
      "Test Loss: -13.434820737457276\n",
      "EPOCH 7\n",
      "Train Loss kd: 9.724167734384537e-07\n",
      "Test Loss -0.0014074976941299438\n",
      " Top 1:  Accuracy: 8913.0/10000 (89.13%)\n",
      "Test Loss: -14.074976941299438\n",
      "EPOCH 8\n",
      "Train Loss kd: 1.8406803905963898e-06\n",
      "Test Loss -0.0014442880730819703\n",
      " Top 1:  Accuracy: 8887.0/10000 (88.87%)\n",
      "Test Loss: -14.442880730819702\n",
      "EPOCH 9\n",
      "Train Loss kd: 3.4435100853443145e-07\n",
      "Test Loss -0.0014840214685440064\n",
      " Top 1:  Accuracy: 8907.0/10000 (89.07%)\n",
      "Test Loss: -14.840214685440063\n",
      "EPOCH 10\n",
      "Train Loss kd: 8.849389851093292e-07\n",
      "Test Loss -0.0015109272653579713\n",
      " Top 1:  Accuracy: 8910.0/10000 (89.10%)\n",
      "Test Loss: -15.109272653579712\n",
      "Accuracy of network on test images is 89.1000....count:1250\n",
      "This took 21.1 minutes\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "\n",
    "VGGcomplete = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "VGGcomplete.make_layers()\n",
    "VGGcomplete._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGcomplete.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGcomplete, pretrained)\n",
    "seq_model_complete = get_seq_model(VGGcomplete)\n",
    "VGGcomplete = VGGcomplete.to(device)\n",
    "seq_model_complete = seq_model_complete.to(device)\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'RandSVD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_complete = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_complete = netadapter_complete.reduce_net(seq_model_complete, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_complete, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "mid1 = time.time()\n",
    "print(\"L'inizializzazione ha impiegato {:.1f} minuti\".format((mid1-start1)/60))\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "\n",
    "optimizer_complete = torch.optim.Adam([{\n",
    "            'params': red_model_complete.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_complete.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_complete.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_complete, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 10\n",
    "filename = './cifar10_VGG16_RedNet_complete_'+str(red_method)+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_complete,\n",
    "            VGGcomplete,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_complete,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_complete, device, test_loader))\n",
    "torch.save([red_model_complete.state_dict(), train_loss, test_loss], filename)\n",
    "end1 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_complete(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "time_VGGcomplete = end1 - start1\n",
    "print('This took {:.1f} minutes'.format(time_VGGcomplete/60), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da VGG non trainata, train_kd per 60 epoche, teacher non trainato (red_method='RandSVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Initializing reduction. Chosen reduction method is: RandSVD\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Siamo alla batch batch 0\n",
      "Siamo alla batch batch 1000\n",
      "Siamo alla batch batch 2000\n",
      "Siamo alla batch batch 3000\n",
      "Siamo alla batch batch 4000\n",
      "Siamo alla batch batch 5000\n",
      "Siamo alla batch batch 6000\n",
      "Le dimensioni delle due matrici sono: proj_mat = torch.Size([4096, 50]) e matrix (input di projection) = torch.Size([50000, 4096])\n",
      "si dovranno moltiplicare alcune righe di input_matrix per proj_matrix\n",
      "proj_mat è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "matrix è salvata su 0 (-1 = cpu, 0 = gpu)\n",
      "Comincia ora il training della FNN\n",
      "Epoch 0 of 500\n",
      "Epoch 50 of 500\n",
      "Epoch 100 of 500\n",
      "Epoch 150 of 500\n",
      "Epoch 200 of 500\n",
      "Epoch 250 of 500\n",
      "Epoch 300 of 500\n",
      "Epoch 350 of 500\n",
      "Epoch 400 of 500\n",
      "Epoch 450 of 500\n",
      "È terminato il training della rete neurale\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=4096, out_features=50, bias=False)\n",
      "  (inout_map): FNN(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=50, out_features=20, bias=True)\n",
      "      (1): Softplus(beta=1, threshold=20)\n",
      "      (2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Tempo di inizializzazione: 8.9 minuti\n",
      "Test Loss 4.283774169611931e-06\n",
      " Top 1:  Accuracy: 5410.0/50000 (10.82%)\n",
      "Test Loss: 0.21418870848059654\n",
      "Test Loss 2.13699599480629e-05\n",
      " Top 1:  Accuracy: 1108.0/10000 (11.08%)\n",
      "Test Loss: 0.21369959948062897\n",
      "EPOCH 1\n",
      "Train Loss kd: 3.085198163986206e-05\n",
      "Test Loss -0.0002968235351467133\n",
      " Top 1:  Accuracy: 5653.0/10000 (56.53%)\n",
      "Test Loss: -2.9682353514671327\n",
      "EPOCH 2\n",
      "Train Loss kd: 2.1830589771270753e-05\n",
      "Test Loss -0.0003176409465122223\n",
      " Top 1:  Accuracy: 6580.0/10000 (65.80%)\n",
      "Test Loss: -3.176409465122223\n",
      "EPOCH 3\n",
      "Train Loss kd: 9.462798833847046e-06\n",
      "Test Loss -0.00036354572869300844\n",
      " Top 1:  Accuracy: 7003.0/10000 (70.03%)\n",
      "Test Loss: -3.6354572869300843\n",
      "EPOCH 4\n",
      "Train Loss kd: 1.0017317533493042e-05\n",
      "Test Loss -0.00043103798798561097\n",
      " Top 1:  Accuracy: 7300.0/10000 (73.00%)\n",
      "Test Loss: -4.31037987985611\n",
      "EPOCH 5\n",
      "Train Loss kd: 6.839514970779419e-06\n",
      "Test Loss -0.00040601447641372683\n",
      " Top 1:  Accuracy: 7394.0/10000 (73.94%)\n",
      "Test Loss: -4.060144764137268\n",
      "EPOCH 6\n",
      "Train Loss kd: 1.4283113479614257e-05\n",
      "Test Loss -0.0004339734431362152\n",
      " Top 1:  Accuracy: 7490.0/10000 (74.90%)\n",
      "Test Loss: -4.339734431362152\n",
      "EPOCH 7\n",
      "Train Loss kd: 7.977029085159301e-06\n",
      "Test Loss -0.0004311580157089233\n",
      " Top 1:  Accuracy: 7583.0/10000 (75.83%)\n",
      "Test Loss: -4.311580157089233\n",
      "EPOCH 8\n",
      "Train Loss kd: 1.5557762384414673e-05\n",
      "Test Loss -0.0004945510966873169\n",
      " Top 1:  Accuracy: 7679.0/10000 (76.79%)\n",
      "Test Loss: -4.945510966873169\n",
      "EPOCH 9\n",
      "Train Loss kd: 2.9439306259155273e-06\n",
      "Test Loss -0.00048673616957664486\n",
      " Top 1:  Accuracy: 7674.0/10000 (76.74%)\n",
      "Test Loss: -4.867361695766449\n",
      "EPOCH 10\n",
      "Train Loss kd: 2.0703363418579103e-05\n",
      "Test Loss -0.0004766175905895233\n",
      " Top 1:  Accuracy: 7787.0/10000 (77.87%)\n",
      "Test Loss: -4.766175905895233\n",
      "EPOCH 11\n",
      "Train Loss kd: 7.185776233673096e-06\n",
      "Test Loss -0.0004802993135261536\n",
      " Top 1:  Accuracy: 7783.0/10000 (77.83%)\n",
      "Test Loss: -4.802993135261536\n",
      "EPOCH 12\n",
      "Train Loss kd: 1.880871057510376e-05\n",
      "Test Loss -0.000475733023071289\n",
      " Top 1:  Accuracy: 7786.0/10000 (77.86%)\n",
      "Test Loss: -4.75733023071289\n",
      "EPOCH 13\n",
      "Train Loss kd: 2.2540380954742433e-05\n",
      "Test Loss -0.00048565350029945373\n",
      " Top 1:  Accuracy: 7807.0/10000 (78.07%)\n",
      "Test Loss: -4.856535002994537\n",
      "EPOCH 14\n",
      "Train Loss kd: 8.799399137496949e-06\n",
      "Test Loss -0.00048715900652885436\n",
      " Top 1:  Accuracy: 7773.0/10000 (77.73%)\n",
      "Test Loss: -4.871590065288544\n",
      "EPOCH 15\n",
      "Train Loss kd: 7.030194997787476e-06\n",
      "Test Loss -0.0005081902284526825\n",
      " Top 1:  Accuracy: 7861.0/10000 (78.61%)\n",
      "Test Loss: -5.081902284526825\n",
      "EPOCH 16\n",
      "Train Loss kd: 6.007720232009888e-06\n",
      "Test Loss -0.0005096759251308441\n",
      " Top 1:  Accuracy: 7893.0/10000 (78.93%)\n",
      "Test Loss: -5.096759251308441\n",
      "EPOCH 17\n",
      "Train Loss kd: 6.517670154571533e-06\n",
      "Test Loss -0.0005100987594795227\n",
      " Top 1:  Accuracy: 7883.0/10000 (78.83%)\n",
      "Test Loss: -5.100987594795227\n",
      "EPOCH 18\n",
      "Train Loss kd: 3.110442876815796e-05\n",
      "Test Loss -0.000518784776468277\n",
      " Top 1:  Accuracy: 7895.0/10000 (78.95%)\n",
      "Test Loss: -5.18784776468277\n",
      "EPOCH 19\n",
      "Train Loss kd: 2.6129014492034912e-05\n",
      "Test Loss -0.0005106213228034973\n",
      " Top 1:  Accuracy: 7914.0/10000 (79.14%)\n",
      "Test Loss: -5.1062132280349735\n",
      "EPOCH 20\n",
      "Train Loss kd: 9.374704957008362e-06\n",
      "Test Loss -0.0005196066655921936\n",
      " Top 1:  Accuracy: 7955.0/10000 (79.55%)\n",
      "Test Loss: -5.196066655921936\n",
      "EPOCH 21\n",
      "Train Loss kd: 7.161612510681153e-06\n",
      "Test Loss -0.0005288377851867676\n",
      " Top 1:  Accuracy: 7940.0/10000 (79.40%)\n",
      "Test Loss: -5.288377851867676\n",
      "EPOCH 22\n",
      "Train Loss kd: 6.127814650535584e-06\n",
      "Test Loss -0.0005399948195266723\n",
      " Top 1:  Accuracy: 7960.0/10000 (79.60%)\n",
      "Test Loss: -5.399948195266724\n",
      "EPOCH 23\n",
      "Train Loss kd: 6.987037658691406e-06\n",
      "Test Loss -0.0005121017329883576\n",
      " Top 1:  Accuracy: 7986.0/10000 (79.86%)\n",
      "Test Loss: -5.121017329883576\n",
      "EPOCH 24\n",
      "Train Loss kd: 5.040544271469116e-06\n",
      "Test Loss -0.0005331921718406677\n",
      " Top 1:  Accuracy: 7986.0/10000 (79.86%)\n",
      "Test Loss: -5.331921718406678\n",
      "EPOCH 25\n",
      "Train Loss kd: 9.268978238105775e-06\n",
      "Test Loss -0.0005315390538883209\n",
      " Top 1:  Accuracy: 7972.0/10000 (79.72%)\n",
      "Test Loss: -5.315390538883209\n",
      "EPOCH 26\n",
      "Train Loss kd: 7.694196701049804e-06\n",
      "Test Loss -0.0005328850677013397\n",
      " Top 1:  Accuracy: 8008.0/10000 (80.08%)\n",
      "Test Loss: -5.328850677013397\n",
      "EPOCH 27\n",
      "Train Loss kd: 8.752757906913758e-06\n",
      "Test Loss -0.0005371592317962646\n",
      " Top 1:  Accuracy: 7981.0/10000 (79.81%)\n",
      "Test Loss: -5.371592317962646\n",
      "EPOCH 28\n",
      "Train Loss kd: 4.276314377784729e-06\n",
      "Test Loss -0.0005307480262947083\n",
      " Top 1:  Accuracy: 8020.0/10000 (80.20%)\n",
      "Test Loss: -5.307480262947083\n",
      "EPOCH 29\n",
      "Train Loss kd: 1.372249960899353e-05\n",
      "Test Loss -0.0005379972716712952\n",
      " Top 1:  Accuracy: 8064.0/10000 (80.64%)\n",
      "Test Loss: -5.379972716712952\n",
      "EPOCH 30\n",
      "Train Loss kd: 7.934610843658447e-06\n",
      "Test Loss -0.0005347429509925842\n",
      " Top 1:  Accuracy: 8041.0/10000 (80.41%)\n",
      "Test Loss: -5.347429509925842\n",
      "EPOCH 31\n",
      "Train Loss kd: 2.5988078117370607e-05\n",
      "Test Loss -0.0005543337230873108\n",
      " Top 1:  Accuracy: 8009.0/10000 (80.09%)\n",
      "Test Loss: -5.5433372308731075\n",
      "EPOCH 32\n",
      "Train Loss kd: 6.771384477615356e-06\n",
      "Test Loss -0.0005424835192680359\n",
      " Top 1:  Accuracy: 8049.0/10000 (80.49%)\n",
      "Test Loss: -5.424835192680359\n",
      "EPOCH 33\n",
      "Train Loss kd: 1.0611644983291626e-05\n",
      "Test Loss -0.0005325335393333435\n",
      " Top 1:  Accuracy: 8043.0/10000 (80.43%)\n",
      "Test Loss: -5.325335393333435\n",
      "EPOCH 34\n",
      "Train Loss kd: 8.148918151855469e-06\n",
      "Test Loss -0.0005345905589199066\n",
      " Top 1:  Accuracy: 8057.0/10000 (80.57%)\n",
      "Test Loss: -5.3459055891990666\n",
      "EPOCH 35\n",
      "Train Loss kd: 4.861398935317993e-06\n",
      "Test Loss -0.0005470682322692871\n",
      " Top 1:  Accuracy: 8069.0/10000 (80.69%)\n",
      "Test Loss: -5.470682322692871\n",
      "EPOCH 36\n",
      "Train Loss kd: 5.379488468170166e-06\n",
      "Test Loss -0.0005516598398971558\n",
      " Top 1:  Accuracy: 8055.0/10000 (80.55%)\n",
      "Test Loss: -5.516598398971557\n",
      "EPOCH 37\n",
      "Train Loss kd: 5.726274251937866e-06\n",
      "Test Loss -0.0005400110046577454\n",
      " Top 1:  Accuracy: 8052.0/10000 (80.52%)\n",
      "Test Loss: -5.400110046577454\n",
      "EPOCH 38\n",
      "Train Loss kd: 5.0589108467102055e-06\n",
      "Test Loss -0.0005400964671707153\n",
      " Top 1:  Accuracy: 8070.0/10000 (80.70%)\n",
      "Test Loss: -5.400964671707153\n",
      "EPOCH 39\n",
      "Train Loss kd: 5.497564077377319e-06\n",
      "Test Loss -0.0005451465631866455\n",
      " Top 1:  Accuracy: 8092.0/10000 (80.92%)\n",
      "Test Loss: -5.451465631866455\n",
      "EPOCH 40\n",
      "Train Loss kd: 1.3533586263656617e-05\n",
      "Test Loss -0.0005451225232124329\n",
      " Top 1:  Accuracy: 8077.0/10000 (80.77%)\n",
      "Test Loss: -5.451225232124329\n",
      "EPOCH 41\n",
      "Train Loss kd: 1.671309471130371e-05\n",
      "Test Loss -0.0005493983985519409\n",
      " Top 1:  Accuracy: 8098.0/10000 (80.98%)\n",
      "Test Loss: -5.493983985519409\n",
      "EPOCH 42\n",
      "Train Loss kd: 9.281996488571166e-06\n",
      "Test Loss -0.0005566374369239807\n",
      " Top 1:  Accuracy: 8103.0/10000 (81.03%)\n",
      "Test Loss: -5.566374369239807\n",
      "EPOCH 43\n",
      "Train Loss kd: 3.972132802009582e-06\n",
      "Test Loss -0.0005562111005020142\n",
      " Top 1:  Accuracy: 8088.0/10000 (80.88%)\n",
      "Test Loss: -5.562111005020141\n",
      "EPOCH 44\n",
      "Train Loss kd: 2.4150916934013367e-06\n",
      "Test Loss -0.0005620588845252991\n",
      " Top 1:  Accuracy: 8093.0/10000 (80.93%)\n",
      "Test Loss: -5.620588845252991\n",
      "EPOCH 45\n",
      "Train Loss kd: 1.5060923099517823e-05\n",
      "Test Loss -0.0005501550687122344\n",
      " Top 1:  Accuracy: 8106.0/10000 (81.06%)\n",
      "Test Loss: -5.501550687122345\n",
      "EPOCH 46\n",
      "Train Loss kd: 1.1495429277420044e-05\n",
      "Test Loss -0.0005625247885513305\n",
      " Top 1:  Accuracy: 8097.0/10000 (80.97%)\n",
      "Test Loss: -5.625247885513305\n",
      "EPOCH 47\n",
      "Train Loss kd: 9.627195000648498e-06\n",
      "Test Loss -0.0005529981529998779\n",
      " Top 1:  Accuracy: 8112.0/10000 (81.12%)\n",
      "Test Loss: -5.529981529998779\n",
      "EPOCH 48\n",
      "Train Loss kd: 9.74557101726532e-06\n",
      "Test Loss -0.0005543588297843933\n",
      " Top 1:  Accuracy: 8093.0/10000 (80.93%)\n",
      "Test Loss: -5.543588297843933\n",
      "EPOCH 49\n",
      "Train Loss kd: 1.601367235183716e-05\n",
      "Test Loss -0.0005584059447669982\n",
      " Top 1:  Accuracy: 8100.0/10000 (81.00%)\n",
      "Test Loss: -5.584059447669983\n",
      "EPOCH 50\n",
      "Train Loss kd: 1.0874011516571045e-05\n",
      "Test Loss -0.0005600618976020814\n",
      " Top 1:  Accuracy: 8108.0/10000 (81.08%)\n",
      "Test Loss: -5.600618976020813\n",
      "EPOCH 51\n",
      "Train Loss kd: 6.773438453674316e-06\n",
      "Test Loss -0.0005630921397399903\n",
      " Top 1:  Accuracy: 8111.0/10000 (81.11%)\n",
      "Test Loss: -5.630921397399902\n",
      "EPOCH 52\n",
      "Train Loss kd: 1.3045269250869752e-05\n",
      "Test Loss -0.0005713004588317872\n",
      " Top 1:  Accuracy: 8118.0/10000 (81.18%)\n",
      "Test Loss: -5.7130045883178715\n",
      "EPOCH 53\n",
      "Train Loss kd: 6.547430753707886e-06\n",
      "Test Loss -0.0005617919310379028\n",
      " Top 1:  Accuracy: 8128.0/10000 (81.28%)\n",
      "Test Loss: -5.617919310379028\n",
      "EPOCH 54\n",
      "Train Loss kd: 7.862774729728699e-06\n",
      "Test Loss -0.0005550115429496765\n",
      " Top 1:  Accuracy: 8149.0/10000 (81.49%)\n",
      "Test Loss: -5.550115429496765\n",
      "EPOCH 55\n",
      "Train Loss kd: 7.523307800292969e-06\n",
      "Test Loss -0.000566960957775116\n",
      " Top 1:  Accuracy: 8133.0/10000 (81.33%)\n",
      "Test Loss: -5.669609577751159\n",
      "EPOCH 56\n",
      "Train Loss kd: 4.060288667678833e-06\n",
      "Test Loss -0.0005670592875099183\n",
      " Top 1:  Accuracy: 8148.0/10000 (81.48%)\n",
      "Test Loss: -5.6705928750991825\n",
      "EPOCH 57\n",
      "Train Loss kd: 9.60849940776825e-06\n",
      "Test Loss -0.0005592977694129944\n",
      " Top 1:  Accuracy: 8166.0/10000 (81.66%)\n",
      "Test Loss: -5.592977694129944\n",
      "EPOCH 58\n",
      "Train Loss kd: 8.236624598503114e-06\n",
      "Test Loss -0.0005695729835891724\n",
      " Top 1:  Accuracy: 8141.0/10000 (81.41%)\n",
      "Test Loss: -5.695729835891724\n",
      "EPOCH 59\n",
      "Train Loss kd: 8.423439860343933e-06\n",
      "Test Loss -0.0005642156186676026\n",
      " Top 1:  Accuracy: 8156.0/10000 (81.56%)\n",
      "Test Loss: -5.642156186676026\n",
      "EPOCH 60\n",
      "Train Loss kd: 6.752180457115174e-06\n",
      "Test Loss -0.0005638416209220886\n",
      " Top 1:  Accuracy: 8146.0/10000 (81.46%)\n",
      "Test Loss: -5.638416209220886\n",
      "Accuracy of network on test images is 81.4600....count:1250\n",
      "Tempo totale 83.3 seconds\n"
     ]
    }
   ],
   "source": [
    "start3 = time.time()\n",
    "\n",
    "\n",
    "VGGmix = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGmix = VGGmix.to(device)\n",
    "VGGmix.make_layers()\n",
    "VGGmix._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGmix.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "seq_model_mix = get_seq_model(VGGmix)\n",
    "VGGmix = VGGmix.to(device)\n",
    "seq_model_mix = seq_model_mix.to(device)\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'RandSVD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_mix = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_mix = netadapter_mix.reduce_net(seq_model_mix, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_mix, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "mid3 = time.time()\n",
    "print('Tempo di inizializzazione: {:.1f} minuti'.format((mid3 -start3)/60), flush=True)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_mix = torch.optim.Adam([{\n",
    "            'params': red_model_mix.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_mix.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_mix.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_mix, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_mix, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet_mix'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_mix,\n",
    "            VGGmix,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_mix,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_mix, device, test_loader))\n",
    "#torch.save([red_model_mix.state_dict(), train_loss, test_loss], filename)\n",
    "\n",
    "end3 = time.time()\n",
    "time_VGGmix = end3 - start3\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mix(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() \n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "\n",
    "print('Tempo totale {:.1f} minutes'.format(time_VGGmix/60), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da una VGG non trainata e con red_model trainato per 60 epoche rispetto un teacher trainato (red_method = 'POD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start4 = time.time()\n",
    "\n",
    "\n",
    "VGGmixtrained = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "VGGmixtrained.make_layers()\n",
    "VGGmixtrained._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGmixtrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "seq_model_mixtrained = get_seq_model(VGGmixtrained)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "seq_model_mixtrained = seq_model_mixtrained.to(device)\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'POD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_mixtrained = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_mixtrained = netadapter_mixtrained.reduce_net(seq_model_mixtrained, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_mixtrained, flush=True)\n",
    "\n",
    "\n",
    "mid4 = time.time()\n",
    "print('Tempo di inizializzazione: {} minuti'.format((mid4 -start4)/60), flush=True)\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "optimizer_mixtrained = torch.optim.Adam([{\n",
    "            'params': red_model_mixtrained.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_mixtrained, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet_mixtrained'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "VGGteacher = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "VGGteacher.make_layers()\n",
    "VGGteacher._initialize_weights()\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.SGD(VGGteacher.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGteacher, pretrained)\n",
    "seq_model_teacher = get_seq_model(VGGteacher)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "seq_model_teacher = seq_model_teacher.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_mixtrained,\n",
    "            VGGteacher,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_mixtrained,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "#torch.save([red_model_mixtrained.state_dict(), train_loss, test_loss], filename)\n",
    "end4 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mixtrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() \n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "time_VGGmixtrained = end4 - start4\n",
    "print(time_VGGmixtrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy della rete ridotta a partire da una VGG non trainata e con red_model trainato per 60 epoche rispetto un teacher trainato (red_method = 'RandSVD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start4 = time.time()\n",
    "\n",
    "\n",
    "VGGmixtrained = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "VGGmixtrained.make_layers()\n",
    "VGGmixtrained._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGmixtrained.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "seq_model_mixtrained = get_seq_model(VGGmixtrained)\n",
    "VGGmixtrained = VGGmixtrained.to(device)\n",
    "seq_model_mixtrained = seq_model_mixtrained.to(device)\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "red_method = 'RandSVD' \n",
    "inout_method = 'FNN'\n",
    "n_class = 10\n",
    "\n",
    "netadapter_mixtrained = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model_mixtrained = netadapter_mixtrained.reduce_net(seq_model_mixtrained, train_dataset, train_labels, train_loader, n_class).to(device)\n",
    "print(red_model_mixtrained, flush=True)\n",
    "\n",
    "\n",
    "mid4 = time.time()\n",
    "print('Tempo di inizializzazione: {} minuti'.format((mid4 -start4)/60), flush=True)\n",
    "\n",
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "optimizer_mixtrained = torch.optim.Adam([{\n",
    "            'params': red_model_mixtrained.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model_mixtrained.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model_mixtrained, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet_mixtrained'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "VGGteacher = VGG(cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "VGGteacher.make_layers()\n",
    "VGGteacher._initialize_weights()\n",
    "criterion_teacher = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.SGD(VGGteacher.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "load_checkpoint(VGGteacher, pretrained)\n",
    "seq_model_teacher = get_seq_model(VGGteacher)\n",
    "VGGteacher = VGGteacher.to(device)\n",
    "seq_model_teacher = seq_model_teacher.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model_mixtrained,\n",
    "            VGGteacher,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer_mixtrained,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model_mixtrained, device, test_loader))\n",
    "#torch.save([red_model_mixtrained.state_dict(), train_loss, test_loss], filename)\n",
    "end4 = time.time()\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = red_model_mixtrained(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() \n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}....count:{}'.format(100*correct/total, count), flush=True)\n",
    "\n",
    "time_VGGmixtrained = end4 - start4\n",
    "print(time_VGGmixtrained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
