{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create reduced version of SSD300\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "import pickle\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.models.aux_conv import AuxiliaryConvolutions\n",
    "from smithers.ml.models.predictor import PredictionConvolutions\n",
    "from smithers.ml.dataset.pascalvoc_dataset import PascalVOCDataset\n",
    "from smithers.ml.models.detector import Detector, Reduced_Detector\n",
    "from smithers.ml.models.utils import create_prior_boxes, save_checkpoint_objdet\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "from smithers.ml.utils import get_seq_model, Total_param, Total_flops\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: {'cat': 1, 'dog': 2, 'background': 0}\n",
      "n_classes: 3\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Learning parameters\n",
    "batch_size = 8  # batch size\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "iterations = 120000  # number of iterations to train\n",
    "print_freq = 200  # print training status every __ batches\n",
    "lr = 1e-4  # learning rate\n",
    "decay_lr_at = [80000, 100000]  # decay learning rate after these many iterations\n",
    "decay_lr_to = 0.1\n",
    "# decay learning rate to this fraction of the existing learning rate\n",
    "#n_classes = 6\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay\n",
    "grad_clip = None\n",
    "# clip if gradients are exploding, which may happen at larger batch sizes\n",
    "\n",
    "voc_labels = ('cat', 'dog')\n",
    "'''voc_labels = ('aeroplane', 'bicycle', 'bird', 'boat',\n",
    "        'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "        'cow', 'diningtable', 'dog', 'horse',\n",
    "        'motorbike', 'person', 'pottedplant',\n",
    "        'sheep', 'sofa', 'train', 'tvmonitor')'''\n",
    "label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n",
    "label_map['background'] = 0\n",
    "n_classes = len(label_map)\n",
    "print('categories:',label_map)\n",
    "print('n_classes:', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 240\n",
      "Testing images: 60\n"
     ]
    }
   ],
   "source": [
    "# Data parameters\n",
    "data_folder = 'VOC_dog_cat/JSONfiles' #folder with json data files\n",
    "keep_difficult = True\n",
    "\n",
    "\n",
    "train_dataset = PascalVOCDataset(data_folder,\n",
    "                                 split='train',\n",
    "                                 keep_difficult=keep_difficult)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_dataset.collate_fn,\n",
    "    num_workers=workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "epochs = iterations // (len(train_dataset) // 32)\n",
    "decay_lr_at = [it // (len(train_dataset) // 32) for it in decay_lr_at]\n",
    "print('Training images:', len(train_dataset))\n",
    "# Load test data\n",
    "test_dataset = PascalVOCDataset(data_folder,\n",
    "                                split='test',\n",
    "                                keep_difficult=keep_difficult)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          collate_fn=test_dataset.collate_fn,\n",
    "                                          num_workers=workers,\n",
    "                                          pin_memory=True)\n",
    "print('Testing images:', len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCTION VIA AHOSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (32): Flatten(start_dim=1, end_dim=-1)\n",
      "  (33): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (34): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Initializing reduction. Chosen reduction method is: HOSVD\n",
      "Initializing dataset forwarding\n",
      "Dataset forwarding complete\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): tensor_product_layer(in_dimensions=[256, 38, 38], out_dimensions=[35, 3, 3])\n",
      "  (inout_map): Identity()\n",
      ")\n",
      "tensor_product_layer(in_dimensions=[256, 38, 38], out_dimensions=[35, 3, 3])\n",
      "La shape di priors_cxcy Ã¨ torch.Size([5926, 4])\n",
      "time needed to initialize the model 12.939788579940796\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = 'checkpoint_ssd300.pth.tar'\n",
    "init_time = time()\n",
    "\n",
    "#base_net = VGG(classifier='ssd', init_weights=False, pretrain_weights=checkpoint)\n",
    "base_net = VGG(classifier='ssd', init_weights=False)\n",
    "seq_model = get_seq_model(base_net)\n",
    "print(seq_model)\n",
    "cutoff_idx = 7\n",
    "mode_list_batch=[2, 35, 3, 3]\n",
    "red_dim = 3 * 3 * 35\n",
    "red_method = 'HOSVD'\n",
    "inout_method = None\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model = netadapter.reduce_net(seq_model, train_dataset, None, train_loader, n_classes, device = device, mode_list_batch = mode_list_batch)\n",
    "print(red_model)\n",
    "base_net = red_model.premodel\n",
    "aux_conv = red_model.proj_model\n",
    "print(aux_conv)\n",
    "#cfg_tot_ssd = [512,1024,] #channel number\n",
    "#cfg_tot = [256, 50] #, 512, 256, 256, 256] #no hosvd\n",
    "cfg_tot = [256, 35] #, 512, 256, 256, 256] #per hosvd\n",
    "n_boxes = [4, 6]\n",
    "predictor = PredictionConvolutions(n_classes, cfg_tot, n_boxes)\n",
    "network = [base_net, aux_conv, predictor]\n",
    "\n",
    "#create prior boxes custom for reduced net\n",
    "#fmaps_dims = {'premodel': 38, 'projmodel': 1} #no hosvd\n",
    "fmaps_dims = {'premodel': 38, 'projmodel': 5}\n",
    "obj_scales = {'premodel': 0.1, 'projmodel': 0.725} #0.9\n",
    "aspect_ratio = {'premodel': [1., 2., 0.5], 'projmodel': [1., 2., 3., 0.5, 0.333]}\n",
    "priors_cxcy = create_prior_boxes(fmaps_dims, obj_scales, aspect_ratio)\n",
    "print(f'La shape di priors_cxcy Ã¨ {priors_cxcy.shape}', flush = True)\n",
    "init_end = time()\n",
    "print('time needed to initialize the model', init_end - init_time)\n",
    "\n",
    "#img_path = 'VOC_cat-dog/JPEGImages/000122.jpg'\n",
    "#img_path = 'VOC_cat-dog/JPEGImages/002215.jpg'\n",
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/001462.jpg'\n",
    "\n",
    "\n",
    "original_image = Image.open(img_path, mode='r')\n",
    "original_image = original_image.convert('RGB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCTION VIA POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (32): Flatten(start_dim=1, end_dim=-1)\n",
      "  (33): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (34): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Initializing reduction. Chosen reduction method is: POD\n",
      "Initializing dataset forwarding\n",
      "Dataset forwarding complete\n",
      "RedNet(\n",
      "  (premodel): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  )\n",
      "  (proj_model): Linear(in_features=369664, out_features=50, bias=False)\n",
      "  (inout_map): Identity()\n",
      ")\n",
      "Linear(in_features=369664, out_features=50, bias=False)\n",
      "time needed to initialize the model 6.380904674530029\n"
     ]
    }
   ],
   "source": [
    "#checkpoint = 'checkpoint_ssd300.pth.tar'\n",
    "init_time = time()\n",
    "\n",
    "#base_net = VGG(classifier='ssd', init_weights=False, pretrain_weights=checkpoint)\n",
    "base_net = VGG(classifier='ssd', init_weights=False)\n",
    "seq_model = get_seq_model(base_net)\n",
    "print(seq_model)\n",
    "cutoff_idx = 7\n",
    "red_dim = 35\n",
    "red_method = 'POD'\n",
    "inout_method = None\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "red_model = netadapter.reduce_net(seq_model, train_dataset, None, train_loader, n_classes)\n",
    "print(red_model)\n",
    "base_net = red_model.premodel\n",
    "aux_conv = red_model.proj_model\n",
    "print(aux_conv)\n",
    "cfg_tot = [256, 50] #, 512, 256, 256, 256]\n",
    "n_boxes = [4, 6]\n",
    "predictor = PredictionConvolutions(n_classes, cfg_tot, n_boxes)\n",
    "network = [base_net, aux_conv, predictor]\n",
    "\n",
    "#create prior boxes custom for reduced net\n",
    "#fmaps_dims = {'premodel': 38, 'projmodel': 1} #non hosvd\n",
    "fmaps_dims = {'premodel': 38, 'projmodel': 1}\n",
    "obj_scales = {'premodel': 0.1, 'projmodel': 0.725} #0.9\n",
    "aspect_ratio = {'premodel': [1., 2., 0.5], 'projmodel': [1., 2., 3., 0.5, 0.333]}\n",
    "priors_cxcy = create_prior_boxes(fmaps_dims, obj_scales, aspect_ratio)\n",
    "\n",
    "init_end = time()\n",
    "print('time needed to initialize the model', init_end - init_time)\n",
    "\n",
    "#img_path = 'VOC_cat-dog/JPEGImages/000122.jpg'\n",
    "#img_path = 'VOC_cat-dog/JPEGImages/002215.jpg'\n",
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/001462.jpg'\n",
    "\n",
    "\n",
    "original_image = Image.open(img_path, mode='r')\n",
    "original_image = original_image.convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 35, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.model[1]\n",
    "img_path = '/u/s/szanin/Smithers/smithers/ml/tutorials/VOC_dog_cat/JPEGImages/002215.jpg'\n",
    "prova = torch.randn((2,256,38,38)).to(device)\n",
    "output_prova = detector.model[1](prova).shape\n",
    "output_prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "), tensor_product_layer(in_dimensions=[256, 38, 38], out_dimensions=[35, 3, 3]), PredictionConvolutions(\n",
      "  (features_loc): Sequential(\n",
      "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(35, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (features_cl): Sequential(\n",
      "    (0): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(35, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")]\n",
      "Training has started.\n",
      "Il tipo di out_vgg Ã¨ <class 'torch.Tensor'>\n",
      "\n",
      "Il tipo di output_auxconv Ã¨ <class 'torch.Tensor'>\n",
      "n_priors Ã¨ 5926\n",
      "predicted_locs.size(1) Ã¨ 5830\n",
      "predicted_scores.size(1) Ã¨ 5830\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb Cella 9\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mcheck = torch.load(check)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mmodel = check['model']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m                  rednet_storage[2], rednet_storage[3]))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m start \u001b[39m=\u001b[39m time()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m check, loss_value \u001b[39m=\u001b[39m detector\u001b[39m.\u001b[39;49mtrain_detector()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m end \u001b[39m=\u001b[39m time()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/Smithers/smithers/ml/tutorials/reduction_SSD.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtÃ¬me needed for train and test\u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m-\u001b[39mstart)\n",
      "File \u001b[0;32m~/Smithers/smithers/ml/models/detector.py:290\u001b[0m, in \u001b[0;36mDetector.train_detector\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         adjust_learning_rate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecay_lr_to)\n\u001b[1;32m    289\u001b[0m     \u001b[39m# One epoch's training\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m     loss_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m    291\u001b[0m     loss_values\u001b[39m.\u001b[39mextend([loss_val])\n\u001b[1;32m    293\u001b[0m \u001b[39m# Save checkpoint\u001b[39;00m\n",
      "File \u001b[0;32m~/Smithers/smithers/ml/models/detector.py:240\u001b[0m, in \u001b[0;36mDetector.train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    236\u001b[0m predicted_locs, predicted_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(images)\n\u001b[1;32m    237\u001b[0m \u001b[39m# (N, 8732, 4), (N, 8732, n_classes)\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[39m# Loss\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion(predicted_locs, predicted_scores, boxes,\n\u001b[1;32m    241\u001b[0m                       labels)  \u001b[39m# scalar\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m# Backward prop.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Smithers/smithers/ml/models/multibox_loss.py:95\u001b[0m, in \u001b[0;36mMultiBoxLoss.forward\u001b[0;34m(self, predicted_locs, predicted_scores, boxes, labels)\u001b[0m\n\u001b[1;32m     93\u001b[0m n_classes \u001b[39m=\u001b[39m predicted_scores\u001b[39m.\u001b[39msize(\u001b[39m2\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn_priors Ã¨ \u001b[39m\u001b[39m{\u001b[39;00mn_priors\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mpredicted_locs.size(1) Ã¨ \u001b[39m\u001b[39m{\u001b[39;00mpredicted_locs\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mpredicted_scores.size(1) Ã¨ \u001b[39m\u001b[39m{\u001b[39;00mpredicted_scores\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 95\u001b[0m \u001b[39massert\u001b[39;00m n_priors \u001b[39m==\u001b[39m predicted_locs\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m predicted_scores\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m     97\u001b[0m true_locs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((batch_size, n_priors, \u001b[39m4\u001b[39m),\n\u001b[1;32m     98\u001b[0m                         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mto(device)  \u001b[39m# (N, 8732, 4)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m true_classes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((batch_size, n_priors),\n\u001b[1;32m    100\u001b[0m                            dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mto(device)  \u001b[39m# (N, 8732)\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check = None\n",
    "epochs = 1\n",
    "start = time()\n",
    "print(epochs)\n",
    "detector = Reduced_Detector(network, check, priors_cxcy, n_classes, epochs,\n",
    "                    batch_size, print_freq, lr, decay_lr_at,\n",
    "                    decay_lr_to, momentum, weight_decay, grad_clip,\n",
    "                    train_loader, test_loader)\n",
    "#check = save_checkpoint(0, network, None)\n",
    "print(detector.model)\n",
    "'''\n",
    "check = torch.load(check)\n",
    "model = check['model']\n",
    "\n",
    "rednet_storage = torch.zeros(4)\n",
    "rednet_flops = torch.zeros(4)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2], rednet_storage[3] = [\n",
    "       Total_param(model[0]),\n",
    "       Total_param(model[1]),\n",
    "       Total_param(model[2].features_loc),\n",
    "       Total_param(model[2].features_cl)]\n",
    "\n",
    "\n",
    "print('SSD300 reduced-storage_init')\n",
    "print(\n",
    "      ' Pre nnz = {:.2f}, POD_model nnz={:.2f}, feature_loc nnz={:.4f}, feature_cl nnz={:.4f}'.format(\n",
    "                  rednet_storage[0], rednet_storage[1],\n",
    "                  rednet_storage[2], rednet_storage[3]))\n",
    "'''\n",
    "\n",
    "start = time()\n",
    "check, loss_value = detector.train_detector()\n",
    "end = time()\n",
    "print('tÃ¬me needed for train and test', end-start)\n",
    "\n",
    "\n",
    "start_test = time()\n",
    "check = 'checkpoint_ssd300.pth.tar'\n",
    "detector.eval_detector(label_map, check)\n",
    "detector.detect(original_image,\n",
    "                check,\n",
    "                label_map,\n",
    "                min_score=0.01,\n",
    "                max_overlap=0.45,\n",
    "                top_k=5).show()\n",
    "end_test = time()\n",
    "print('Time needed to test the detector', end_test-start_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD300 reduced-storage\n",
      " Pre nnz = 6.62, POD_model nnz=70.51, feature_loc nnz=0.1820, feature_cl nnz=0.1365\n"
     ]
    }
   ],
   "source": [
    "#check = 'checkpoint_ssd300_red_pascalvoc.pth.tar'\n",
    "#check = 'checkpoint_ssd300.pth.tar'\n",
    "check = torch.load(check)\n",
    "model = check['model']\n",
    "\n",
    "rednet_storage = torch.zeros(4)\n",
    "rednet_flops = torch.zeros(4)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2], rednet_storage[3] = [\n",
    "       Total_param(model[0]),\n",
    "       Total_param(model[1]),\n",
    "       Total_param(model[2].features_loc),\n",
    "       Total_param(model[2].features_cl)]\n",
    "\n",
    "\n",
    "#rednet_flops[0], rednet_flops[1], rednet_flops[2], rednet_flops[3] = [\n",
    "#        Total_flops(model[0], device),\n",
    "#        Total_flops(model[1], device),\n",
    "#        Total_flops(model[2].features_loc, device),\n",
    "#        Total_flops(model[2].features_cl, device)]\n",
    "\n",
    "print('SSD300 reduced-storage')\n",
    "print(\n",
    "      ' Pre nnz = {:.2f}, POD_model nnz={:.2f}, feature_loc nnz={:.4f}, feature_cl nnz={:.4f}'.format(\n",
    "                  rednet_storage[0], rednet_storage[1],\n",
    "                  rednet_storage[2], rednet_storage[3]))\n",
    "\n",
    "#        print(\n",
    "#              '   flops:  Pre = {:.2f}, POD_model = {:.2f}, ANN ={:.2f}'.format(\n",
    "#                  rednet_flops[0], rednet_flops[1], rednet_flops[2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD300-storage\n",
      " Pre nnz = 78.14, aux_model nnz=9.38, feature_loc nnz=2.0395, feature_cl nnz=1.5296\n",
      " Pre nnz = 78.14, pre_vgg nnz=56.13, pre_avgpool nnz=0.0000, pre_classifier nnz=22.0078\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check1 = 'checkpoint_ssd300_pascal_catdog_500.pth.tar'\n",
    "#check1 = 'checkpoint_ssd300_catdog_500_new.pth.tar'\n",
    "check1 = 'checkpoint_ssd300.pth.tar'\n",
    "check1 = torch.load(check1)\n",
    "model = check1['model']\n",
    "\n",
    "rednet_storage = torch.zeros(4)\n",
    "rednet_flops = torch.zeros(4)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2], rednet_storage[3]  = [\n",
    "       Total_param(model[0]),\n",
    "       Total_param(model[1].features),\n",
    "       Total_param(model[2].features_loc),\n",
    "       Total_param(model[2].features_cl)]\n",
    "\n",
    "rednet_vgg_storage = torch.zeros(4)\n",
    "rednet_vgg_storage[0], rednet_vgg_storage[1], rednet_vgg_storage[2], rednet_vgg_storage[3],  = [\n",
    "       Total_param(model[0]),\n",
    "       Total_param(model[0].features),\n",
    "       Total_param(model[0].avgpool),\n",
    "       Total_param(model[0].classifier)]\n",
    "\n",
    "#rednet_flops[0], rednet_flops[1], rednet_flops[2], rednet_flops[3] = [\n",
    "#        Total_flops(model[0], device),\n",
    "#        Total_flops(model[1], device),\n",
    "#        Total_flops(model[2].features_loc, device),\n",
    "#        Total_flops(model[2].features_cl, device)]\n",
    "\n",
    "\n",
    "print('SSD300-storage')\n",
    "print(\n",
    "      ' Pre nnz = {:.2f}, aux_model nnz={:.2f}, feature_loc nnz={:.4f}, feature_cl nnz={:.4f}'.format(\n",
    "                  rednet_storage[0], rednet_storage[1],\n",
    "                  rednet_storage[2], rednet_storage[3]))\n",
    "\n",
    "\"\"\"print(\n",
    "      ' Pre nnz = {:.2f}, pre_vgg nnz={:.2f}, pre_avgpool nnz={:.4f}, pre_classifier nnz={:.4f}'.format(\n",
    "                  rednet_vgg_storage[0], rednet_vgg_storage[1],\n",
    "                  rednet_vgg_storage[2], rednet_vgg_storage[3]))\"\"\"\n",
    "\n",
    "\n",
    "torch.save(detector, 'check_ssd300_red.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
