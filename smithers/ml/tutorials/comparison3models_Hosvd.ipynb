{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n",
      "\n",
      "Loaded base model.\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initializing reduction. Chosen reduction method is: AHOSVD\n",
      "Inizio forwarding dataset\n",
      "La shape di out_model è torch.Size([50000, 256, 4, 4])\n",
      "Fine forwarding dataset\n",
      "La shape di tensor_red è torch.Size([50000, 35, 3, 3])\n",
      "La shape di flattened_red_out_model è torch.Size([50000, 315])\n",
      "Comincia ora il training della FNN\n",
      "È terminato il training della rete neurale\n",
      "l'inizzializzazione ha impiegato 10.719153467814127 minuti\n",
      "Test Loss 5.526361733680964e-06\n",
      " Top 1:  Accuracy: 4962.0/50000 (9.92%)\n",
      "Test Loss: 0.27631808668404817\n",
      "Test Loss 4.710970412254333e-05\n",
      " Top 1:  Accuracy: 1057.0/10000 (10.57%)\n",
      "Test Loss: 0.47109704122543333\n",
      "EPOCH 1\n",
      "Train Loss kd: 1.98233163356781e-05\n",
      "Test Loss -0.0003493409291219711\n",
      " Top 1:  Accuracy: 7384.0/10000 (73.84%)\n",
      "Test Loss: -3.493409291219711\n",
      "EPOCH 2\n",
      "Train Loss kd: 5.5418318510055545e-06\n",
      "Test Loss -0.00044395178874969484\n",
      " Top 1:  Accuracy: 7943.0/10000 (79.43%)\n",
      "Test Loss: -4.439517887496948\n",
      "EPOCH 3\n",
      "Train Loss kd: 1.5331838130950926e-05\n",
      "Test Loss -0.0004949185995960236\n",
      " Top 1:  Accuracy: 8139.0/10000 (81.39%)\n",
      "Test Loss: -4.949185995960236\n",
      "EPOCH 4\n",
      "Train Loss kd: 1.3902699947357178e-05\n",
      "Test Loss -0.0005432286873197556\n",
      " Top 1:  Accuracy: 8236.0/10000 (82.36%)\n",
      "Test Loss: -5.4322868731975555\n",
      "EPOCH 5\n",
      "Train Loss kd: 7.535343766212463e-06\n",
      "Test Loss -0.0004933515171813965\n",
      " Top 1:  Accuracy: 8320.0/10000 (83.20%)\n",
      "Test Loss: -4.933515171813965\n",
      "EPOCH 6\n",
      "Train Loss kd: 1.355289340019226e-05\n",
      "Test Loss -0.0005501741401290894\n",
      " Top 1:  Accuracy: 8356.0/10000 (83.56%)\n",
      "Test Loss: -5.501741401290894\n",
      "EPOCH 7\n",
      "Train Loss kd: 2.192167341709137e-06\n",
      "Test Loss -0.0005531065395832062\n",
      " Top 1:  Accuracy: 8452.0/10000 (84.52%)\n",
      "Test Loss: -5.531065395832062\n",
      "EPOCH 8\n",
      "Train Loss kd: 3.0154314637184142e-06\n",
      "Test Loss -0.0005649523440361023\n",
      " Top 1:  Accuracy: 8469.0/10000 (84.69%)\n",
      "Test Loss: -5.649523440361023\n",
      "EPOCH 9\n",
      "Train Loss kd: 1.2988688945770264e-05\n",
      "Test Loss -0.0005692054106044769\n",
      " Top 1:  Accuracy: 8508.0/10000 (85.08%)\n",
      "Test Loss: -5.692054106044769\n",
      "EPOCH 10\n",
      "Train Loss kd: 1.888551115989685e-06\n",
      "Test Loss -0.0005696828764820099\n",
      " Top 1:  Accuracy: 8498.0/10000 (84.98%)\n",
      "Test Loss: -5.696828764820099\n",
      "EPOCH 11\n",
      "Train Loss kd: 6.460154056549072e-06\n",
      "Test Loss -0.0005543784506320953\n",
      " Top 1:  Accuracy: 8531.0/10000 (85.31%)\n",
      "Test Loss: -5.543784506320954\n",
      "EPOCH 12\n",
      "Train Loss kd: 7.786384224891663e-07\n",
      "Test Loss -0.0005850867210674286\n",
      " Top 1:  Accuracy: 8560.0/10000 (85.60%)\n",
      "Test Loss: -5.850867210674286\n",
      "EPOCH 13\n",
      "Train Loss kd: 1.1284573078155518e-05\n",
      "Test Loss -0.0005947658896827698\n",
      " Top 1:  Accuracy: 8568.0/10000 (85.68%)\n",
      "Test Loss: -5.947658896827698\n",
      "EPOCH 14\n",
      "Train Loss kd: 8.44082772731781e-06\n",
      "Test Loss -0.0005817728018665313\n",
      " Top 1:  Accuracy: 8570.0/10000 (85.70%)\n",
      "Test Loss: -5.8177280186653135\n",
      "EPOCH 15\n",
      "Train Loss kd: 4.506533741950989e-06\n",
      "Test Loss -0.0005958988798427582\n",
      " Top 1:  Accuracy: 8603.0/10000 (86.03%)\n",
      "Test Loss: -5.958988798427582\n",
      "EPOCH 16\n",
      "Train Loss kd: 2.924812138080597e-06\n",
      "Test Loss -0.0005962211315155029\n",
      " Top 1:  Accuracy: 8629.0/10000 (86.29%)\n",
      "Test Loss: -5.962211315155029\n",
      "EPOCH 17\n",
      "Train Loss kd: 8.4196537733078e-06\n",
      "Test Loss -0.000611553145942688\n",
      " Top 1:  Accuracy: 8620.0/10000 (86.20%)\n",
      "Test Loss: -6.1155314594268795\n",
      "EPOCH 18\n",
      "Train Loss kd: 2.536957859992981e-06\n",
      "Test Loss -0.0006061374851465225\n",
      " Top 1:  Accuracy: 8636.0/10000 (86.36%)\n",
      "Test Loss: -6.061374851465225\n",
      "EPOCH 19\n",
      "Train Loss kd: 1.4959312975406646e-06\n",
      "Test Loss -0.0006256538474655152\n",
      " Top 1:  Accuracy: 8645.0/10000 (86.45%)\n",
      "Test Loss: -6.256538474655152\n",
      "EPOCH 20\n",
      "Train Loss kd: 3.5082727670669558e-06\n",
      "Test Loss -0.000595007994480133\n",
      " Top 1:  Accuracy: 8625.0/10000 (86.25%)\n",
      "Test Loss: -5.95007994480133\n",
      "EPOCH 21\n",
      "Train Loss kd: 4.270902276039124e-06\n",
      "Test Loss -0.0006231375525856018\n",
      " Top 1:  Accuracy: 8658.0/10000 (86.58%)\n",
      "Test Loss: -6.231375525856018\n",
      "EPOCH 22\n",
      "Train Loss kd: 5.267783403396606e-06\n",
      "Test Loss -0.0006202829280662536\n",
      " Top 1:  Accuracy: 8672.0/10000 (86.72%)\n",
      "Test Loss: -6.202829280662536\n",
      "EPOCH 23\n",
      "Train Loss kd: 4.922222495079041e-06\n",
      "Test Loss -0.0006434455130195618\n",
      " Top 1:  Accuracy: 8648.0/10000 (86.48%)\n",
      "Test Loss: -6.434455130195618\n",
      "EPOCH 24\n",
      "Train Loss kd: 2.7960580587387083e-06\n",
      "Test Loss -0.0006495279026317596\n",
      " Top 1:  Accuracy: 8687.0/10000 (86.87%)\n",
      "Test Loss: -6.495279026317596\n",
      "EPOCH 25\n",
      "Train Loss kd: 4.491459131240845e-06\n",
      "Test Loss -0.0006572001696395874\n",
      " Top 1:  Accuracy: 8658.0/10000 (86.58%)\n",
      "Test Loss: -6.572001696395874\n",
      "EPOCH 26\n",
      "Train Loss kd: 1.1686842888593673e-06\n",
      "Test Loss -0.0006394900790023803\n",
      " Top 1:  Accuracy: 8674.0/10000 (86.74%)\n",
      "Test Loss: -6.3949007900238035\n",
      "EPOCH 27\n",
      "Train Loss kd: 4.335303604602814e-06\n",
      "Test Loss -0.0006328669623756409\n",
      " Top 1:  Accuracy: 8664.0/10000 (86.64%)\n",
      "Test Loss: -6.328669623756409\n",
      "EPOCH 28\n",
      "Train Loss kd: 4.100082516670227e-06\n",
      "Test Loss -0.0006371060219097138\n",
      " Top 1:  Accuracy: 8686.0/10000 (86.86%)\n",
      "Test Loss: -6.371060219097138\n",
      "EPOCH 29\n",
      "Train Loss kd: 7.644336819648742e-06\n",
      "Test Loss -0.0006630773819875718\n",
      " Top 1:  Accuracy: 8680.0/10000 (86.80%)\n",
      "Test Loss: -6.630773819875717\n",
      "EPOCH 30\n",
      "Train Loss kd: 1.697520911693573e-06\n",
      "Test Loss -0.0006313917272281647\n",
      " Top 1:  Accuracy: 8663.0/10000 (86.63%)\n",
      "Test Loss: -6.313917272281647\n",
      "EPOCH 31\n",
      "Train Loss kd: 6.5824228525161744e-06\n",
      "Test Loss -0.0006588948748970032\n",
      " Top 1:  Accuracy: 8689.0/10000 (86.89%)\n",
      "Test Loss: -6.588948748970032\n",
      "EPOCH 32\n",
      "Train Loss kd: 1.8795577809214592e-07\n",
      "Test Loss -0.0006493021018409729\n",
      " Top 1:  Accuracy: 8698.0/10000 (86.98%)\n",
      "Test Loss: -6.493021018409729\n",
      "EPOCH 33\n",
      "Train Loss kd: 5.0166743993759155e-06\n",
      "Test Loss -0.0006524149831867218\n",
      " Top 1:  Accuracy: 8675.0/10000 (86.75%)\n",
      "Test Loss: -6.524149831867218\n",
      "EPOCH 34\n",
      "Train Loss kd: 1.9904853403568266e-06\n",
      "Test Loss -0.0006551087256145477\n",
      " Top 1:  Accuracy: 8663.0/10000 (86.63%)\n",
      "Test Loss: -6.551087256145477\n",
      "EPOCH 35\n",
      "Train Loss kd: 6.483364850282669e-07\n",
      "Test Loss -0.0006519562126159668\n",
      " Top 1:  Accuracy: 8700.0/10000 (87.00%)\n",
      "Test Loss: -6.519562126159668\n",
      "EPOCH 36\n",
      "Train Loss kd: 1.5443362295627594e-06\n",
      "Test Loss -0.0006842506689071655\n",
      " Top 1:  Accuracy: 8686.0/10000 (86.86%)\n",
      "Test Loss: -6.842506689071655\n",
      "EPOCH 37\n",
      "Train Loss kd: 8.080793619155883e-06\n",
      "Test Loss -0.0006543519111156463\n",
      " Top 1:  Accuracy: 8711.0/10000 (87.11%)\n",
      "Test Loss: -6.5435191111564635\n",
      "EPOCH 38\n",
      "Train Loss kd: 3.2243046164512636e-06\n",
      "Test Loss -0.0006584496043491364\n",
      " Top 1:  Accuracy: 8712.0/10000 (87.12%)\n",
      "Test Loss: -6.584496043491363\n",
      "EPOCH 39\n",
      "Train Loss kd: 7.4627643823623655e-06\n",
      "Test Loss -0.0006697123483276366\n",
      " Top 1:  Accuracy: 8711.0/10000 (87.11%)\n",
      "Test Loss: -6.697123483276367\n",
      "EPOCH 40\n",
      "Train Loss kd: 3.070608377456665e-06\n",
      "Test Loss -0.0006674655626487733\n",
      " Top 1:  Accuracy: 8708.0/10000 (87.08%)\n",
      "Test Loss: -6.674655626487732\n",
      "EPOCH 41\n",
      "Train Loss kd: 6.455907821655274e-06\n",
      "Test Loss -0.0006753128908061982\n",
      " Top 1:  Accuracy: 8697.0/10000 (86.97%)\n",
      "Test Loss: -6.753128908061981\n",
      "EPOCH 42\n",
      "Train Loss kd: 1.070258617401123e-05\n",
      "Test Loss -0.0006767684637451172\n",
      " Top 1:  Accuracy: 8718.0/10000 (87.18%)\n",
      "Test Loss: -6.767684637451172\n",
      "EPOCH 43\n",
      "Train Loss kd: 4.404894709587097e-06\n",
      "Test Loss -0.0006622479635047912\n",
      " Top 1:  Accuracy: 8714.0/10000 (87.14%)\n",
      "Test Loss: -6.622479635047912\n",
      "EPOCH 44\n",
      "Train Loss kd: 1.7995715141296387e-06\n",
      "Test Loss -0.0006818212960910797\n",
      " Top 1:  Accuracy: 8720.0/10000 (87.20%)\n",
      "Test Loss: -6.818212960910797\n",
      "EPOCH 45\n",
      "Train Loss kd: 3.834234476089478e-06\n",
      "Test Loss -0.0006640593026733399\n",
      " Top 1:  Accuracy: 8733.0/10000 (87.33%)\n",
      "Test Loss: -6.640593026733399\n",
      "EPOCH 46\n",
      "Train Loss kd: 7.243273258209229e-06\n",
      "Test Loss -0.0006798593905162812\n",
      " Top 1:  Accuracy: 8720.0/10000 (87.20%)\n",
      "Test Loss: -6.798593905162812\n",
      "EPOCH 47\n",
      "Train Loss kd: 2.6921483874320985e-06\n",
      "Test Loss -0.0006703081118965149\n",
      " Top 1:  Accuracy: 8700.0/10000 (87.00%)\n",
      "Test Loss: -6.703081118965149\n",
      "EPOCH 48\n",
      "Train Loss kd: 1.4618903398513794e-06\n",
      "Test Loss -0.0006592866931152344\n",
      " Top 1:  Accuracy: 8740.0/10000 (87.40%)\n",
      "Test Loss: -6.592866931152344\n",
      "EPOCH 49\n",
      "Train Loss kd: 1.2318861484527588e-06\n",
      "Test Loss -0.0006716289984226226\n",
      " Top 1:  Accuracy: 8738.0/10000 (87.38%)\n",
      "Test Loss: -6.7162899842262265\n",
      "EPOCH 50\n",
      "Train Loss kd: 2.72868275642395e-07\n",
      "Test Loss -0.0006865213817977906\n",
      " Top 1:  Accuracy: 8716.0/10000 (87.16%)\n",
      "Test Loss: -6.865213817977906\n",
      "EPOCH 51\n",
      "Train Loss kd: 3.4745536744594574e-07\n",
      "Test Loss -0.0006796481489562988\n",
      " Top 1:  Accuracy: 8734.0/10000 (87.34%)\n",
      "Test Loss: -6.796481489562988\n",
      "EPOCH 52\n",
      "Train Loss kd: 4.206864908337593e-07\n",
      "Test Loss -0.0006792073351097107\n",
      " Top 1:  Accuracy: 8722.0/10000 (87.22%)\n",
      "Test Loss: -6.792073351097107\n",
      "EPOCH 53\n",
      "Train Loss kd: 5.573011040687561e-06\n",
      "Test Loss -0.0006697758127641678\n",
      " Top 1:  Accuracy: 8739.0/10000 (87.39%)\n",
      "Test Loss: -6.697758127641678\n",
      "EPOCH 54\n",
      "Train Loss kd: 9.565097093582154e-07\n",
      "Test Loss -0.0006784131432533264\n",
      " Top 1:  Accuracy: 8739.0/10000 (87.39%)\n",
      "Test Loss: -6.784131432533264\n",
      "EPOCH 55\n",
      "Train Loss kd: 1.6968877613544464e-06\n",
      "Test Loss -0.0006768466056919098\n",
      " Top 1:  Accuracy: 8735.0/10000 (87.35%)\n",
      "Test Loss: -6.768466056919098\n",
      "EPOCH 56\n",
      "Train Loss kd: 2.3160116374492647e-06\n",
      "Test Loss -0.000686617953605652\n",
      " Top 1:  Accuracy: 8745.0/10000 (87.45%)\n",
      "Test Loss: -6.866179536056519\n",
      "EPOCH 57\n",
      "Train Loss kd: 6.459631323814392e-06\n",
      "Test Loss -0.0006729732940006256\n",
      " Top 1:  Accuracy: 8746.0/10000 (87.46%)\n",
      "Test Loss: -6.729732940006256\n",
      "EPOCH 58\n",
      "Train Loss kd: 3.805433809757233e-06\n",
      "Test Loss -0.0006866830985832214\n",
      " Top 1:  Accuracy: 8724.0/10000 (87.24%)\n",
      "Test Loss: -6.866830985832214\n",
      "EPOCH 59\n",
      "Train Loss kd: 2.515117824077606e-06\n",
      "Test Loss -0.0006895617144584656\n",
      " Top 1:  Accuracy: 8729.0/10000 (87.29%)\n",
      "Test Loss: -6.895617144584656\n",
      "EPOCH 60\n",
      "Train Loss kd: 1.8368372321128846e-06\n",
      "Test Loss -0.0006791731033325196\n",
      " Top 1:  Accuracy: 8731.0/10000 (87.31%)\n",
      "Test Loss: -6.7917310333251955\n",
      "In tutto la procedura ha impiegato 85.72981159687042 minuti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.utils import get_seq_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from smithers.ml.utils import randomized_range_finder\n",
    "from smithers.ml.utils import randomized_svd\n",
    "from smithers.ml.AHOSVD import AHOSVD\n",
    "\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "start1 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "VGGnet = VGG(    cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGnet = VGGnet.to(device) #MODIF\n",
    "VGGnet.make_layers()\n",
    "VGGnet._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "VGGnet2 = VGG(    cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGnet = VGGnet.to(device) #MODIF\n",
    "VGGnet.make_layers()\n",
    "VGGnet._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGnet.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint_torch(epoch, model, path, optimizer):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8 #this can be changed\n",
    "data_path = '../datasets/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "model2 = VGGnet2\n",
    "#load_checkpoint(model2, pretrained)\n",
    "seq_model2 = get_seq_model(model2)\n",
    "model2 = model2.to(device) #MODIF\n",
    "seq_model2 = seq_model2.to(device) #MODIF\n",
    "\n",
    "\n",
    "seq_model2.eval()\n",
    "\n",
    "model = VGGnet\n",
    "load_checkpoint(model, pretrained)\n",
    "seq_model = get_seq_model(model)\n",
    "model = model.to(device) #MODIF\n",
    "seq_model = seq_model.to(device) #MODIF\n",
    "\n",
    "\n",
    "seq_model.eval()\n",
    "\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "red_dim = 35 * 3 * 3\n",
    "red_method = 'AHOSVD'\n",
    "inout_method = 'FNN'\n",
    "n_class = 10 \n",
    "\n",
    "cutoff_idx = 7\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, 'HOSVD', inout_method)\n",
    "red_model = netadapter.reduce_net_AHOSVD(seq_model2, train_dataset, train_labels, train_loader, n_class, mode_list_batch = [25, 35, 3, 3], device = device)\n",
    "\n",
    "print(f\"l'inizzializzazione ha impiegato {(time.time()-start1)/60} minuti\")\n",
    "\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "optimizer = torch.optim.Adam([{\n",
    "            'params': red_model.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 60\n",
    "filename = './cifar10_VGG16_RedNet'+'HOSVD'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model,\n",
    "            model,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "\n",
    "print(f\"In tutto la procedura ha impiegato {(time.time()-start1)/60} minuti\")\n",
    "#torch.save([red_model.state_dict(), train_loss, test_loss], filename)\n",
    "#torch.save([red_model.state_dict()], 'AHOSVD_temp.pth') #TEMPORANEO, SI PUÒ TOGLIERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
