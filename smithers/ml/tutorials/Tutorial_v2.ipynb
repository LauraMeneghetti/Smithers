{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 reduction tutorial\n",
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "from smithers.ml.vgg import VGG\n",
    "from smithers.ml.utils import get_seq_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from smithers.ml.utils import randomized_range_finder\n",
    "from smithers.ml.utils import randomized_svd\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETTING PROPER DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINIZIONE VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VGGnet = VGG(    cfg=None,\n",
    "                 classifier='cifar',\n",
    "                 batch_norm=False,\n",
    "                 num_classes=10,\n",
    "                 init_weights=False,\n",
    "                 pretrain_weights=None)\n",
    "VGGnet = VGGnet.to(device) #MODIF\n",
    "VGGnet.make_layers()\n",
    "VGGnet._initialize_weights()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNZIONI PER IMPORT E EXPORT DEI MODELLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_torch(epoch, model, path, optimizer):\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DEL DATASET CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8 #this can be changed\n",
    "data_path = '../datasets/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING (UNCOMMENT IF NO CHECKPOINT AVAILABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' print(\\'inizio training\\', flush=True)\\nprint(\\'Training iniziato\\') #MODIF\\nfor epoch in range(60):  # loop over the dataset multiple times\\n    print(\"Inizia ora l\\'epoca \"+str(epoch), flush=True)\\n    running_loss = 0.0\\n    for i, data in enumerate(train_loader, 0):\\n        # get the inputs; data is a list of [inputs, labels]\\n        inputs, labels = data\\n        inputs = inputs.to(device)\\n        labels = labels.to(device)\\n\\n\\n        # zero the parameter gradients\\n        optimizer.zero_grad()\\n\\n        # forward + backward + optimize\\n        outputs = VGGnet(inputs)\\n        outputs = outputs[1]\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        # print statistics\\n        running_loss += loss.item()\\n        #if i % 2000 == 1999:    # print every 2000 mini-batches\\n        if i % 200 == 199:    # print every 200 mini-batches #MODIF\\n            print(\\'[%d, %5d] loss: %.3f\\' %\\n                  (epoch + 1, i + 1, running_loss / 2000), flush=True)\\n            running_loss = 0.0\\n\\n\\n\\n\\nsave_checkpoint_torch(60, VGGnet, \\'/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_stefano.pth.tar\\', optimizer)\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" print('inizio training', flush=True)\n",
    "print('Training iniziato') #MODIF\n",
    "for epoch in range(60):  # loop over the dataset multiple times\n",
    "    print(\"Inizia ora l'epoca \"+str(epoch), flush=True)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = VGGnet(inputs)\n",
    "        outputs = outputs[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        if i % 200 == 199:    # print every 200 mini-batches #MODIF\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000), flush=True)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_checkpoint_torch(60, VGGnet, '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_stefano.pth.tar', optimizer)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING A CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = '/u/s/szanin/Smithers/smithers/ml/tutorials/check_vgg_cifar10_60_v2.pth.tar' #Stefano's\n",
    "model = VGGnet\n",
    "load_checkpoint(model, pretrained)\n",
    "seq_model = get_seq_model(model)\n",
    "model = model.to(device) #MODIF\n",
    "seq_model = seq_model.to(device) #MODIF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY OF THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on test images is 88.8200\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "VGGnet.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device))\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "print('Accuracy of network on test images is {:.4f}'.format(100*correct/total), flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDUCTION OF VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on test images is 88.2917....count: 300\n",
      "Accuracy of network on test images is 88.4167....count: 600\n",
      "Accuracy of network on test images is 88.5556....count: 900\n",
      "Accuracy of network on test images is 88.7396....count: 1200\n",
      "RandSVD 50\n",
      "Initializing reduction. Chosen reduction method is: RandSVD\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb Cella 18\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m netadapter \u001b[39m=\u001b[39m NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(netadapter\u001b[39m.\u001b[39mred_method, netadapter\u001b[39m.\u001b[39mred_dim, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m red_model \u001b[39m=\u001b[39m netadapter\u001b[39m.\u001b[39;49mreduce_net(seq_model, train_dataset, train_labels, train_loader, n_class)\u001b[39m.\u001b[39mto(device) \u001b[39m#MODIF\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(red_model, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/netadapter.py:254\u001b[0m, in \u001b[0;36mNetAdapter.reduce_net\u001b[0;34m(self, input_network, train_dataset, train_labels, train_loader, n_class)\u001b[0m\n\u001b[1;32m    252\u001b[0m post_model \u001b[39m=\u001b[39m input_network[cut_idxlayer:]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39minput_type)\n\u001b[1;32m    253\u001b[0m out_model \u001b[39m=\u001b[39m forward_dataset(input_network, train_loader)\n\u001b[0;32m--> 254\u001b[0m matrix_red, proj_mat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(pre_model, post_model,\n\u001b[1;32m    255\u001b[0m                                     train_dataset, train_loader)\n\u001b[1;32m    256\u001b[0m inout_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inout_mapping(matrix_red, n_class, out_model,\n\u001b[1;32m    257\u001b[0m                                 train_labels, train_loader)\n\u001b[1;32m    258\u001b[0m reduced_net \u001b[39m=\u001b[39m RedNet(n_class, pre_model, proj_mat, inout_map)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/netadapter.py:133\u001b[0m, in \u001b[0;36mNetAdapter._reduce\u001b[0;34m(self, pre_model, post_model, train_dataset, train_loader)\u001b[0m\n\u001b[1;32m    129\u001b[0m     proj_mat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce_POD(matrix_features)\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mred_method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRandSVD\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m#MODIF\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39m#code for RandSVD\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     proj_mat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce_RandSVD(matrix_features)\n\u001b[1;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/netadapter.py:98\u001b[0m, in \u001b[0;36mNetAdapter._reduce_RandSVD\u001b[0;34m(self, matrix_features)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reduce_RandSVD\u001b[39m(\u001b[39mself\u001b[39m, matrix_features): \u001b[39m#MODIF\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    Function that performs the reduction using the Randomized SVD (RandSVD).\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    :param torch.Tensor matrix_features: (n_images x n_feat) matrix\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m    :rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     u, s, v \u001b[39m=\u001b[39m randomized_svd(matrix_features, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mred_dim)\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m u\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/utils.py:518\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandomized_svd\u001b[39m(M, n_components, n_oversamples\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m    516\u001b[0m     n_random \u001b[39m=\u001b[39m n_components \u001b[39m+\u001b[39m n_oversamples\n\u001b[0;32m--> 518\u001b[0m     Q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(randomized_range_finder(M, n_random, n_iter))\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    519\u001b[0m     \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    520\u001b[0m     M \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(M)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/utils.py:509\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter)\u001b[0m\n\u001b[1;32m    506\u001b[0m Q \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(size\u001b[39m=\u001b[39m(A\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], size))\n\u001b[1;32m    508\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter):\n\u001b[0;32m--> 509\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mlu(A \u001b[39m@\u001b[39;49m Q, permute_l\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mlu(A\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m Q, permute_l\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    512\u001b[0m Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mqr(A \u001b[39m@\u001b[39m Q, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meconomic\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/torch/_tensor.py:757\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    756\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    "\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "#red_method = 'POD' \n",
    "red_method = 'RandSVD'\n",
    "inout_method = 'FNN'\n",
    "n_class = 10 #MODIF\n",
    "\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "print(netadapter.red_method, netadapter.red_dim, flush=True)\n",
    "red_model = netadapter.reduce_net(seq_model, train_dataset, train_labels, train_loader, n_class).to(device) #MODIF\n",
    "print(red_model, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on test images is 87.4167....count: 300\n",
      "Accuracy of network on test images is 88.6042....count: 600\n",
      "Accuracy of network on test images is 88.6111....count: 900\n",
      "Accuracy of network on test images is 88.8021....count: 1200\n",
      "RandSVD 50\n",
      "Initializing reduction. Chosen reduction method is: RandSVD\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb Cella 19\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m#matrix_red, proj_mat = netadapter._reduce(pre_model, post_model, train_dataset, train_loader) #### Riga incriminata\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m matrix_features \u001b[39m=\u001b[39m forward_dataset(pre_model, train_loader)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m proj_mat \u001b[39m=\u001b[39m netadapter\u001b[39m.\u001b[39;49m_reduce_RandSVD(matrix_features)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m matrix_red \u001b[39m=\u001b[39m projection(proj_mat, train_loader, matrix_features)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blovelace/u/s/szanin/ZaninStefanoSmithers/smithers/ml/tutorials/Tutorial_v2.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m inout_map \u001b[39m=\u001b[39m netadapter\u001b[39m.\u001b[39m_inout_mapping(matrix_red, n_class, out_model,train_labels, train_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/netadapter.py:98\u001b[0m, in \u001b[0;36mNetAdapter._reduce_RandSVD\u001b[0;34m(self, matrix_features)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_reduce_RandSVD\u001b[39m(\u001b[39mself\u001b[39m, matrix_features): \u001b[39m#MODIF\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    Function that performs the reduction using the Randomized SVD (RandSVD).\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    :param torch.Tensor matrix_features: (n_images x n_feat) matrix\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m    :rtype: torch.Tensor\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     u, s, v \u001b[39m=\u001b[39m randomized_svd(matrix_features, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mred_dim)\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m u\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/utils.py:520\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandomized_svd\u001b[39m(M, n_components, n_oversamples\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_iter\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m    518\u001b[0m     n_random \u001b[39m=\u001b[39m n_components \u001b[39m+\u001b[39m n_oversamples\n\u001b[0;32m--> 520\u001b[0m     Q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(randomized_range_finder(M, n_random, n_iter))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    521\u001b[0m     \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     M \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(M)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/reducedcnn/lib/python3.10/site-packages/smithers-0.0.1-py3.10.egg/smithers/ml/utils.py:511\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m# Q = np.random.normal(size=(A.shape[1], size))\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter):\n\u001b[0;32m--> 511\u001b[0m     Q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mlu(A \u001b[39m@\u001b[39;49m Q)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    512\u001b[0m     Q \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mlu(A\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m Q)[\u001b[39m1\u001b[39m]\n\u001b[1;32m    514\u001b[0m Q, _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mqr(A \u001b[39m@\u001b[39m Q)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    }
   ],
   "source": [
    "#####CELLA AGGIUNTA, SI POTRÃ€ CANCELLARE\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "seq_model.eval()\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = seq_model(test.to(device)) #MODIF\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%300 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    "\n",
    "\n",
    "from smithers.ml.netadapter import NetAdapter\n",
    "\n",
    "cutoff_idx = 7\n",
    "red_dim = 50 \n",
    "#red_method = 'POD' \n",
    "red_method = 'RandSVD'\n",
    "inout_method = 'FNN'\n",
    "n_class = 10 #MODIF\n",
    "\n",
    "netadapter = NetAdapter(cutoff_idx, red_dim, red_method, inout_method)\n",
    "print(netadapter.red_method, netadapter.red_dim, flush=True)\n",
    "\n",
    "#red_model = netadapter.reduce_net(seq_model, train_dataset, train_labels, train_loader, n_class).to(device) #MODIF\n",
    "from smithers.ml.utils import PossibleCutIdx, spatial_gradients, forward_dataset, projection\n",
    "from smithers.ml.rednet import RedNet\n",
    "\n",
    "\n",
    "print('Initializing reduction. Chosen reduction method is: '+netadapter.red_method, flush=True)\n",
    "input_type = train_dataset.__getitem__(0)[0].dtype\n",
    "possible_cut_idx = PossibleCutIdx(seq_model)\n",
    "cut_idxlayer = possible_cut_idx[netadapter.cutoff_idx]\n",
    "pre_model = seq_model[:cut_idxlayer].to(device, dtype=input_type)\n",
    "post_model = seq_model[cut_idxlayer:].to(device, dtype=input_type)\n",
    "out_model = forward_dataset(seq_model, train_loader)\n",
    "#matrix_red, proj_mat = netadapter._reduce(pre_model, post_model, train_dataset, train_loader) #### Riga incriminata\n",
    "matrix_features = forward_dataset(pre_model, train_loader)\n",
    "proj_mat = netadapter._reduce_RandSVD(matrix_features)\n",
    "matrix_red = projection(proj_mat, train_loader, matrix_features)\n",
    "\n",
    "inout_map = netadapter._inout_mapping(matrix_red, n_class, out_model,train_labels, train_loader)\n",
    "reduced_net = RedNet(n_class, pre_model, proj_mat, inout_map)\n",
    "\n",
    "\n",
    "print(red_model, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0117,  0.9208,  0.3108,  1.4690],\n",
       "        [ 0.6546,  0.0175, -0.9479,  2.2479],\n",
       "        [-0.0893, -2.1956,  1.2245, -0.6197],\n",
       "        [ 1.3845,  0.1049,  0.7796,  0.3271]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(4,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4175633 , -0.84560187],\n",
       "       [ 1.3246683 , -0.15937175],\n",
       "       [-0.88493098, -1.21231413],\n",
       "       [-0.26287561, -0.43962654]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(size=(A.shape[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.linalg_lu(\n",
       "P=tensor([[0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]]),\n",
       "L=tensor([[ 1.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0645,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.4728,  0.0147,  1.0000,  0.0000],\n",
       "        [ 0.0084, -0.4203, -0.6291,  1.0000]]),\n",
       "U=tensor([[ 1.3845,  0.1049,  0.7796,  0.3271],\n",
       "        [ 0.0000, -2.1888,  1.2748, -0.5986],\n",
       "        [ 0.0000,  0.0000, -1.3351,  2.1021],\n",
       "        [ 0.0000,  0.0000,  0.0000,  2.5371]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.lu(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of network on test images is 11.5000....count: 50\n",
      "Accuracy of network on test images is 11.6250....count: 100\n",
      "Accuracy of network on test images is 12.2500....count: 150\n",
      "Accuracy of network on test images is 12.6250....count: 200\n",
      "Accuracy of network on test images is 12.2500....count: 250\n",
      "Accuracy of network on test images is 12.2917....count: 300\n",
      "Accuracy of network on test images is 12.0000....count: 350\n",
      "Accuracy of network on test images is 12.1250....count: 400\n",
      "Accuracy of network on test images is 11.7778....count: 450\n",
      "Accuracy of network on test images is 11.8250....count: 500\n",
      "Accuracy of network on test images is 11.8182....count: 550\n",
      "Accuracy of network on test images is 11.8750....count: 600\n",
      "Accuracy of network on test images is 12.0962....count: 650\n",
      "Accuracy of network on test images is 12.3750....count: 700\n",
      "Accuracy of network on test images is 12.2667....count: 750\n",
      "Accuracy of network on test images is 12.2344....count: 800\n",
      "Accuracy of network on test images is 12.2647....count: 850\n",
      "Accuracy of network on test images is 12.1667....count: 900\n",
      "Accuracy of network on test images is 12.3158....count: 950\n",
      "Accuracy of network on test images is 12.3750....count: 1000\n",
      "Accuracy of network on test images is 12.3452....count: 1050\n",
      "Accuracy of network on test images is 12.3182....count: 1100\n",
      "Accuracy of network on test images is 12.3804....count: 1150\n",
      "Accuracy of network on test images is 12.3125....count: 1200\n",
      "Accuracy of network on test images is 12.1900....count: 1250\n",
      "Pre nnz = 6.62, proj_model nnz=0.78, FNN nnz=0.0047\n",
      "flops:  Pre = 190.51, proj_model = 0.20, FNN =0.00\n",
      "Test Loss 9.373777281577587e-05\n",
      " Top 1:  Accuracy: 6754.0/50000 (13.51%)\n",
      "Test Loss: 4.686888640788793\n",
      "Test Loss 0.0006189761897826194\n",
      " Top 1:  Accuracy: 1219.0/10000 (12.19%)\n",
      "Test Loss: 6.189761897826195\n",
      "EPOCH 1\n",
      "Train Loss kd: 9.925905466079711e-06\n",
      "Test Loss -0.0007272260724830627\n",
      " Top 1:  Accuracy: 8312.0/10000 (83.12%)\n",
      "Test Loss: -7.272260724830628\n",
      "EPOCH 2\n",
      "Train Loss kd: 2.305413782596588e-06\n",
      "Test Loss -0.0008504342199325562\n",
      " Top 1:  Accuracy: 8613.0/10000 (86.13%)\n",
      "Test Loss: -8.504342199325562\n",
      "EPOCH 3\n",
      "Train Loss kd: 2.050256431102753e-06\n",
      "Test Loss -0.0009989389088058472\n",
      " Top 1:  Accuracy: 8694.0/10000 (86.94%)\n",
      "Test Loss: -9.989389088058472\n",
      "EPOCH 4\n",
      "Train Loss kd: 9.191638976335525e-07\n",
      "Test Loss -0.0010791712151908875\n",
      " Top 1:  Accuracy: 8777.0/10000 (87.77%)\n",
      "Test Loss: -10.791712151908875\n",
      "EPOCH 5\n",
      "Train Loss kd: 5.242637991905212e-06\n",
      "Test Loss -0.0011411638488006593\n",
      " Top 1:  Accuracy: 8791.0/10000 (87.91%)\n",
      "Test Loss: -11.411638488006592\n",
      "EPOCH 6\n",
      "Train Loss kd: 6.9008725881576535e-06\n",
      "Test Loss -0.0011604691121673584\n",
      " Top 1:  Accuracy: 8824.0/10000 (88.24%)\n",
      "Test Loss: -11.604691121673584\n",
      "EPOCH 7\n",
      "Train Loss kd: 4.994889604859054e-09\n",
      "Test Loss -0.0012493053769111633\n",
      " Top 1:  Accuracy: 8866.0/10000 (88.66%)\n",
      "Test Loss: -12.493053769111633\n",
      "EPOCH 8\n",
      "Train Loss kd: 5.9875994920730595e-06\n",
      "Test Loss -0.0013120758193969726\n",
      " Top 1:  Accuracy: 8848.0/10000 (88.48%)\n",
      "Test Loss: -13.120758193969726\n",
      "EPOCH 9\n",
      "Train Loss kd: 3.2167460769414904e-07\n",
      "Test Loss -0.0013134644196319582\n",
      " Top 1:  Accuracy: 8868.0/10000 (88.68%)\n",
      "Test Loss: -13.13464419631958\n",
      "EPOCH 10\n",
      "Train Loss kd: 1.2930346727371215e-05\n",
      "Test Loss -0.0013528357023239136\n",
      " Top 1:  Accuracy: 8877.0/10000 (88.77%)\n",
      "Test Loss: -13.528357023239137\n"
     ]
    }
   ],
   "source": [
    "from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "\n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3)\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "\n",
    "rednet_flops[0], rednet_flops[1], rednet_flops[2] = [\n",
    "    Total_flops(red_model.premodel, device),\n",
    "    Total_flops(red_model.proj_model, device),\n",
    "    Total_flops(red_model.inout_map, device)]\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "count = 0\n",
    "for test, y_test in iter(test_loader):\n",
    "#Calculate the class probabilities (softmax) for img\n",
    "    with torch.no_grad():\n",
    "        output = red_model(test)\n",
    "        ps = torch.exp(output)\n",
    "        _, predicted = torch.max(output.data,1)\n",
    "        total += y_test.size(0)\n",
    "        correct += (predicted == y_test.to(device)).sum().item() #MODIF\n",
    "        count += 1\n",
    "        #print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count ))\n",
    "        if count%50 == 0:\n",
    "            print(\"Accuracy of network on test images is {:.4f}....count: {}\".format(100*correct/total,  count), flush=True)\n",
    "\n",
    "\n",
    "print(\n",
    "      'Pre nnz = {:.2f}, proj_model nnz={:.2f}, FNN nnz={:.4f}'.format(\n",
    "      rednet_storage[0], rednet_storage[1],\n",
    "      rednet_storage[2]), flush=True)\n",
    "print(\n",
    "      'flops:  Pre = {:.2f}, proj_model = {:.2f}, FNN ={:.2f}'.format(\n",
    "       rednet_flops[0], rednet_flops[1], rednet_flops[2]), flush=True)\n",
    "\n",
    "optimizer = torch.optim.Adam([{\n",
    "            'params': red_model.premodel.parameters(),\n",
    "            'lr': 1e-4\n",
    "            }, {\n",
    "            'params': red_model.proj_model.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }, {\n",
    "            'params': red_model.inout_map.parameters(),\n",
    "            'lr': 1e-5\n",
    "            }])\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_loss.append(compute_loss(red_model, device, train_loader))\n",
    "test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "\n",
    "        \n",
    "epochs = 10\n",
    "filename = './cifar10_VGG16_RedNet'+\\\n",
    "            '_cutIDx_%d.pth'%(cutoff_idx)\n",
    "\n",
    "\"\"\" if os.path.isfile(filename):\n",
    "    [rednet_pretrained, train_loss,test_loss] = torch.load(filename)\n",
    "    red_model.load_state_dict(rednet_pretrained)\n",
    "    print('rednet trained {} epoches is loaded'.format(epochs), flush=True)\n",
    "else:\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_loss.append(compute_loss(red_model, device, train_loader))\n",
    "    test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print('EPOCH {}'.format(epoch), flush=True)\n",
    "        train_loss.append(\n",
    "                train_kd(red_model,\n",
    "                model,\n",
    "                device,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                train_max_batch=200,\n",
    "                alpha=0.1,\n",
    "                temperature=1.,\n",
    "                epoch=epoch))\n",
    "        test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "    torch.save([red_model.state_dict(), train_loss, test_loss], filename) \"\"\"\n",
    "\n",
    "for epoch in range(1, epochs + 1):                       #da qui alla fine era dentro l'else commentato\n",
    "    print('EPOCH {}'.format(epoch), flush=True)\n",
    "    train_loss.append(\n",
    "            train_kd(red_model,\n",
    "            model,\n",
    "            device,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            train_max_batch=200,\n",
    "            alpha=0.1,\n",
    "            temperature=1.,\n",
    "            epoch=epoch))\n",
    "    test_loss.append(compute_loss(red_model, device, test_loader))\n",
    "torch.save([red_model.state_dict(), train_loss, test_loss], filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6204e+00, 7.8125e-01, 4.6921e-03])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\n",
    "\n",
    "rednet_storage = torch.zeros(3)\n",
    "rednet_flops = torch.zeros(3) \"\"\"\n",
    "\n",
    "rednet_storage[0], rednet_storage[1], rednet_storage[2] = [\n",
    "    Total_param(red_model.premodel),\n",
    "    Total_param(red_model.proj_model),\n",
    "    Total_param(red_model.inout_map)]\n",
    "rednet_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([56.1516])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from smithers.ml.utils import Total_param, Total_flops\n",
    "from smithers.ml.utils import compute_loss, train_kd\"\"\"\n",
    "\n",
    "rednet_storage_VGG = torch.zeros(1)\n",
    "\n",
    "rednet_storage_VGG[0] = Total_param(VGGnet)\n",
    "rednet_storage_VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_trial, classes_trial = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(4, device='cuda:0'),\n",
       " tensor(7, device='cuda:0'),\n",
       " tensor(6, device='cuda:0'),\n",
       " tensor(7, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(8, device='cuda:0'),\n",
       " tensor(8, device='cuda:0'),\n",
       " tensor(1, device='cuda:0')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = [torch.argmax(red_model(inputs_trial)[i]) for i in range(8)]\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7, 6, 7, 4, 8, 8, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('reducedcnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
